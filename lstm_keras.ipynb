{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pywt\n",
    "import inspect\n",
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Embedding, LSTM, Activation, Input\n",
    "# from keras.layers import LSTM\n",
    "import scipy.io.wavfile as wavfile\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_rate, input_signal = wavfile.read('data/1clean_Selection.wav')\n",
    "output_rate, output_signal = wavfile.read('data/1Selection.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing out pywt functions and reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input rate: 44100\n",
      "for 5 ms samples, input sample length is: 220\n",
      "Max wave level decomposition: 3\n",
      "input signal shape: (1810432, 2)\n",
      "coefficients shapes: 4, [226320, 226320, 452622, 905225]\n",
      "coefficients type: <type 'numpy.ndarray'>\n",
      "reconstruction shape: (1810432, 2)\n",
      "['bior1.1', 'bior1.3', 'bior1.5', 'bior2.2', 'bior2.4', 'bior2.6', 'bior2.8', 'bior3.1', 'bior3.3', 'bior3.5', 'bior3.7', 'bior3.9', 'bior4.4', 'bior5.5', 'bior6.8', 'cgau1', 'cgau2', 'cgau3', 'cgau4', 'cgau5', 'cgau6', 'cgau7', 'cgau8', 'cmor', 'coif1', 'coif2', 'coif3', 'coif4', 'coif5', 'coif6', 'coif7', 'coif8', 'coif9', 'coif10', 'coif11', 'coif12', 'coif13', 'coif14', 'coif15', 'coif16', 'coif17', 'db1', 'db2', 'db3', 'db4', 'db5', 'db6', 'db7', 'db8', 'db9', 'db10', 'db11', 'db12', 'db13', 'db14', 'db15', 'db16', 'db17', 'db18', 'db19', 'db20', 'db21', 'db22', 'db23', 'db24', 'db25', 'db26', 'db27', 'db28', 'db29', 'db30', 'db31', 'db32', 'db33', 'db34', 'db35', 'db36', 'db37', 'db38', 'dmey', 'fbsp', 'gaus1', 'gaus2', 'gaus3', 'gaus4', 'gaus5', 'gaus6', 'gaus7', 'gaus8', 'haar', 'mexh', 'morl', 'rbio1.1', 'rbio1.3', 'rbio1.5', 'rbio2.2', 'rbio2.4', 'rbio2.6', 'rbio2.8', 'rbio3.1', 'rbio3.3', 'rbio3.5', 'rbio3.7', 'rbio3.9', 'rbio4.4', 'rbio5.5', 'rbio6.8', 'shan', 'sym2', 'sym3', 'sym4', 'sym5', 'sym6', 'sym7', 'sym8', 'sym9', 'sym10', 'sym11', 'sym12', 'sym13', 'sym14', 'sym15', 'sym16', 'sym17', 'sym18', 'sym19', 'sym20']\n"
     ]
    }
   ],
   "source": [
    "# some settings:\n",
    "wavetype = 'db10'\n",
    "# wavelevel = 15\n",
    "\n",
    "print(\"input rate: \" + str(input_rate))\n",
    "sample_length = input_rate//200\n",
    "print(\"for 5 ms samples, input sample length is: \" + str(sample_length))\n",
    "\n",
    "w = pywt.Wavelet(wavetype)\n",
    "wavelevel = pywt.dwt_max_level(data_len=sample_length, filter_len=w.dec_len)\n",
    "\n",
    "# set a little lower:\n",
    "# wavelevel = 1\n",
    "print(\"Max wave level decomposition: \" + str(wavelevel))\n",
    "\n",
    "# these are floats, original is int16\n",
    "input_coeffs1 = pywt.wavedec(input_signal[:,0].T, wavetype, level=wavelevel)\n",
    "input_coeffs2 = pywt.wavedec(input_signal[:,1].T, wavetype, level=wavelevel)\n",
    "# output_coeffs1 = pywt.wavedec(output_signal[:,0].T, wavetype, level=wavelevel)\n",
    "# output_coeffs2 = pywt.wavedec(output_signal[:,1].T, wavetype, level=wavelevel)\n",
    "print(\"input signal shape: \" + str(input_signal.shape))\n",
    "\n",
    "# reconstruction for left and right channel\n",
    "recons1 = np.array([pywt.waverec(input_coeffs1, wavetype)]).astype('int16')\n",
    "recons2 = np.array([pywt.waverec(input_coeffs2, wavetype)]).astype('int16')\n",
    "\n",
    "# print(recons1.shape)\n",
    "print(\"coefficients shapes: \" + str(len(input_coeffs1)) + \", \" + str([len(j) for j in input_coeffs1]))\n",
    "print(\"coefficients type: \" + str(type(input_coeffs1[0])))\n",
    "\n",
    "write_array = np.concatenate((recons1,recons2),axis=0).T\n",
    "print('reconstruction shape: ' + str(write_array.shape))\n",
    "\n",
    "# output wav for auditory test\n",
    "wavfile.write('output/recons.wav', input_rate, write_array)\n",
    "\n",
    "# get available wavelets\n",
    "print(pywt.wavelist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0 -1 -2 -2 -3 -2 -1 -1]\n",
      "[ 0  0  0 -1 -2 -2 -3 -2 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "print(input_signal[:10,0].T)\n",
    "print(recons1[0,:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare data for keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# functions for pre-processing and reconstruction of training vectors\n",
    "# first function is over a batch - need smaller size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of samples: 8229\n",
      "length of different wavelet bands: [33, 33, 60, 113]\n",
      "indexes: [0, 33, 66, 126, 239]\n",
      "more sizes? [33, 33, 60, 113]\n",
      "(8229, 478)\n",
      "[33, 33, 60, 113]\n"
     ]
    }
   ],
   "source": [
    "# DEPRECATED\n",
    "def wavelet_to_vector_all(input_raw, output_raw, chunk_size, wavelet_level, wavelet_type):\n",
    "    current_set = 'input'\n",
    "    \n",
    "    w = pywt.Wavelet(wavelet_type)\n",
    "    max_level = pywt.dwt_max_level(data_len=chunk_size, filter_len=w.dec_len)\n",
    "    if wavelet_level > max_level:\n",
    "        print('wavelet level too high. set to max level: ' + str(max_level))\n",
    "        wavelet_level = max_level\n",
    "    \n",
    "    # short hacky loop\n",
    "    while True:\n",
    "        # select the correct set\n",
    "        if current_set == 'input':\n",
    "            data = input_raw\n",
    "            amount_of_chunks = int(math.floor(data.shape[0]/chunk_size))\n",
    "            input_list = []\n",
    "            print('Amount of samples: ' + str(amount_of_chunks))\n",
    "        else:\n",
    "            data = output_raw\n",
    "            amount_of_chunks = int(math.floor(data.shape[0]/chunk_size))\n",
    "            output_list = []\n",
    "        \n",
    "        index_range = (np.arange(amount_of_chunks) * chunk_size)\n",
    "        indp = chunk_size - 1\n",
    "        # for all chunks do this:\n",
    "        for ind in index_range:\n",
    "#             print(ind)\n",
    "            sample1 = data[ind:ind+indp,0].T\n",
    "            sample2 = data[ind:ind+indp,1].T\n",
    "            coeffs1 = pywt.wavedec(sample1, wavelet_type, level=wavelet_level)\n",
    "            coeffs2 = pywt.wavedec(sample2, wavelet_type, level=wavelet_level)\n",
    "            unfolded1 = np.array([item for sublist in coeffs1 for item in sublist])\n",
    "            unfolded2 = np.array([item for sublist in coeffs2 for item in sublist])\n",
    "            # POSSIBLE MISTAKE: puts l/r in one big sequence\n",
    "            # run on mono first\n",
    "            vector = np.concatenate((unfolded1,unfolded2),axis=0)\n",
    "            \n",
    "            if current_set == 'input':\n",
    "                input_list.append(vector)\n",
    "            else:\n",
    "                output_list.append(vector)\n",
    "#             unf_arr = np.array(unfolded1)\n",
    "#             print(unf_arr.shape)\n",
    "#             print(len(unfolded))\n",
    "            \n",
    "            # for all coeff levels:\n",
    "#             for i in range(len(coeffs1)):\n",
    "#                 print(i)\n",
    "            \n",
    "        \n",
    "        \n",
    "        if current_set == 'output':\n",
    "            break\n",
    "        current_set = 'output'\n",
    "\n",
    "    # convert lists to arrays\n",
    "    input_arr = np.array(input_list)\n",
    "    output_arr = np.array(output_list)\n",
    "    \n",
    "    # print stats for converting back to audio\n",
    "    wavelet_lengths = [len(j) for j in coeffs1]\n",
    "    ind = 0\n",
    "    index_list = [0]\n",
    "    for w_l in wavelet_lengths:\n",
    "        ind += w_l\n",
    "        index_list.append(ind)\n",
    "    print(\"length of different wavelet bands: \" + str(wavelet_lengths))\n",
    "    print(\"indexes: \" + str(index_list))\n",
    "    print(\"more sizes? \" + str([len(sublist) for sublist in coeffs1]))\n",
    "    # return level sizes for reconstruction\n",
    "    level_sizes = []\n",
    "    for cf in coeffs1:\n",
    "        level_sizes.append(cf.shape[0])\n",
    "    return [input_arr, output_arr, level_sizes]\n",
    "# input_coeffs1[16].shape\n",
    "\n",
    "# rows=samples, cols=dim\n",
    "[input_matrix, output_matrix, level_sizes] = wavelet_to_vector_all(input_signal, output_signal, sample_length, wavelevel, 'db4')\n",
    "print(input_matrix.shape)\n",
    "print(level_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices where vector should be sliced: [0, 44, 88, 157, 276]\n"
     ]
    }
   ],
   "source": [
    "# some info\n",
    "wav_lengths = [44, 44, 69, 119]\n",
    "wav_indices = [0]\n",
    "for length in wav_lengths:\n",
    "    wav_indices.append(wav_indices[-1]+length)\n",
    "print(\"indices where vector should be sliced: \" + str(wav_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for a single audio slice (mono)\n",
    "def audio_to_vector(input_mono, wavelet_level, wavelet_type):\n",
    "    coeffs = pywt.wavedec(input_mono, wavelet_type, level=wavelet_level)\n",
    "#     print([len(co) for co in coeffs])\n",
    "#     vector = np.array([item for sublist in coeffs for item in sublist])\n",
    "#     vector = np.array([])\n",
    "    vector = np.concatenate(coeffs)\n",
    "#     for band in coeffs:\n",
    "#         vector.append\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a single output vector (mono)\n",
    "def vector_to_list(input_vector, indexes=wav_indices):\n",
    "    # unflatten the vector\n",
    "#     for i in range(len(indexes)-1):\n",
    "#         wavelet_list.append(input_vector[indexes[i]:indexes[i+1]])\n",
    "    # use np.split\n",
    "    wavelet_list = np.split(input_vector, indexes[1:-1])\n",
    "    return wavelet_list\n",
    "#     wavelet_list = [input_vector[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector length: 276\n",
      "92415.9154495\n",
      "-83612.7180552\n",
      "87949.0011249\n",
      "-90682.166482\n",
      "92415.9154495\n",
      "(16458, 276)\n"
     ]
    }
   ],
   "source": [
    "# create new (mono) data set\n",
    "# for both channels, we just handle mono samples:\n",
    "mono_input = []\n",
    "mono_output = []\n",
    "for side in (0,1):\n",
    "    total_raw_in = input_signal[:,side]\n",
    "    total_raw_out = output_signal[:,side]\n",
    "    number_of_chunks = total_raw_in.shape[0]//sample_length\n",
    "#     print(number_of_chunks)\n",
    "    for ind in range(number_of_chunks):\n",
    "        start_ind = ind*sample_length\n",
    "        end_ind = ind*sample_length + sample_length\n",
    "        curr_in_sample = total_raw_in[start_ind:end_ind]\n",
    "        curr_out_sample = total_raw_out[start_ind:end_ind]\n",
    "        in_vec = audio_to_vector(curr_in_sample, wavelevel, wavetype)\n",
    "        out_vec = audio_to_vector(curr_out_sample, wavelevel, wavetype)\n",
    "        mono_input.append(in_vec)\n",
    "        mono_output.append(out_vec)\n",
    "#     print(curr_in_sample.shape)\n",
    "vec_length = in_vec.shape[0]\n",
    "print(\"vector length: \" +str(vec_length))\n",
    "mono_input = np.array(mono_input)\n",
    "mono_output = np.array(mono_output)\n",
    "\n",
    "print(np.max(mono_input))\n",
    "print(np.min(mono_input))\n",
    "print(np.max(mono_output))\n",
    "print(np.min(mono_output))\n",
    "# max seems to be about 100000, so scale it to that range:\n",
    "# not necessary for linear activation i think...\n",
    "# mono_input = mono_input/100000\n",
    "# mono_output = mono_output/100000\n",
    "print(np.max(mono_input))\n",
    "\n",
    "print(mono_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3620760)\n",
      "2\n",
      "reconstruction shape: (1810380, 2)\n"
     ]
    }
   ],
   "source": [
    "# now put some of it back into audio form to test the representation's audio quality\n",
    "reconstruction_array = []\n",
    "for i in range(mono_output.shape[0]):\n",
    "    coeffs = vector_to_list(mono_output[i,:])\n",
    "    rec_arr = np.array([pywt.waverec(coeffs, wavetype)]).astype('int16')\n",
    "    reconstruction_array.append(rec_arr)\n",
    "\n",
    "reconstruction_array = np.concatenate(reconstruction_array,axis=1)\n",
    "print(reconstruction_array.shape)\n",
    "# write_array = np.reshape(reconstruction_array, (-1,2))\n",
    "rec_split = np.split(reconstruction_array.T, 2)\n",
    "print(len(rec_split))\n",
    "\n",
    "write_array = np.concatenate((rec_split[0], rec_split[1]),axis=1)\n",
    "print('reconstruction shape: ' + str(write_array.shape))\n",
    "\n",
    "# output wav for auditory test\n",
    "wavfile.write('output/recons_new.wav', input_rate, write_array)\n",
    "# scientific analysis: sounds fine to me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build the first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Epoch 1/70\n",
      "16458/16458 [==============================] - 1s - loss: 10222858.1909     \n",
      "Epoch 2/70\n",
      "16458/16458 [==============================] - 0s - loss: 7824645.4324     \n",
      "Epoch 3/70\n",
      "16458/16458 [==============================] - 0s - loss: 7450747.5291     \n",
      "Epoch 4/70\n",
      "16458/16458 [==============================] - 0s - loss: 7188183.6171     \n",
      "Epoch 5/70\n",
      "16458/16458 [==============================] - 0s - loss: 7019459.5925     \n",
      "Epoch 6/70\n",
      "16458/16458 [==============================] - 0s - loss: 6875931.3513     \n",
      "Epoch 7/70\n",
      "16458/16458 [==============================] - 0s - loss: 6743865.2918     \n",
      "Epoch 8/70\n",
      "16458/16458 [==============================] - 0s - loss: 6644057.2092     \n",
      "Epoch 9/70\n",
      "16458/16458 [==============================] - 0s - loss: 6524816.8172     \n",
      "Epoch 10/70\n",
      "16458/16458 [==============================] - 0s - loss: 6417254.4624     \n",
      "Epoch 11/70\n",
      "16458/16458 [==============================] - 0s - loss: 6329334.7769     \n",
      "Epoch 12/70\n",
      "16458/16458 [==============================] - 0s - loss: 6250746.9008     \n",
      "Epoch 13/70\n",
      "16458/16458 [==============================] - 0s - loss: 6165273.5358     \n",
      "Epoch 14/70\n",
      "16458/16458 [==============================] - 0s - loss: 6090741.7140     \n",
      "Epoch 15/70\n",
      "16458/16458 [==============================] - 0s - loss: 5995061.1551     \n",
      "Epoch 16/70\n",
      "16458/16458 [==============================] - 0s - loss: 5922600.3575     \n",
      "Epoch 17/70\n",
      "16458/16458 [==============================] - 0s - loss: 5851047.4942     \n",
      "Epoch 18/70\n",
      "16458/16458 [==============================] - 0s - loss: 5756211.6585     \n",
      "Epoch 19/70\n",
      "16458/16458 [==============================] - 0s - loss: 5681244.5591     \n",
      "Epoch 20/70\n",
      "16458/16458 [==============================] - 0s - loss: 5619669.7167     \n",
      "Epoch 21/70\n",
      "16458/16458 [==============================] - 0s - loss: 5549623.3525     \n",
      "Epoch 22/70\n",
      "16458/16458 [==============================] - 0s - loss: 5482071.7644     \n",
      "Epoch 23/70\n",
      "16458/16458 [==============================] - 0s - loss: 5431392.8043     \n",
      "Epoch 24/70\n",
      "16458/16458 [==============================] - 0s - loss: 5363715.8595     \n",
      "Epoch 25/70\n",
      "16458/16458 [==============================] - 0s - loss: 5304605.7177     \n",
      "Epoch 26/70\n",
      "16458/16458 [==============================] - 0s - loss: 5234917.4363     \n",
      "Epoch 27/70\n",
      "16458/16458 [==============================] - 0s - loss: 5195607.1665     \n",
      "Epoch 28/70\n",
      "16458/16458 [==============================] - 0s - loss: 5130828.6193     \n",
      "Epoch 29/70\n",
      "16458/16458 [==============================] - 0s - loss: 5104164.9154     \n",
      "Epoch 30/70\n",
      "16458/16458 [==============================] - 0s - loss: 5018611.9606     \n",
      "Epoch 31/70\n",
      "16458/16458 [==============================] - 0s - loss: 4989501.3652     \n",
      "Epoch 32/70\n",
      "16458/16458 [==============================] - 0s - loss: 4927186.6587     \n",
      "Epoch 33/70\n",
      "16458/16458 [==============================] - 0s - loss: 4879231.0608     \n",
      "Epoch 34/70\n",
      "16458/16458 [==============================] - 0s - loss: 4810104.6616     \n",
      "Epoch 35/70\n",
      "16458/16458 [==============================] - 0s - loss: 4789815.5863     \n",
      "Epoch 36/70\n",
      "16458/16458 [==============================] - 0s - loss: 4734978.2045     \n",
      "Epoch 37/70\n",
      "16458/16458 [==============================] - ETA: 0s - loss: 4684135.138 - 0s - loss: 4685679.7400     \n",
      "Epoch 38/70\n",
      "16458/16458 [==============================] - 0s - loss: 4651804.5565     \n",
      "Epoch 39/70\n",
      "16458/16458 [==============================] - 0s - loss: 4594810.8945     \n",
      "Epoch 40/70\n",
      "16458/16458 [==============================] - 0s - loss: 4577604.5407     \n",
      "Epoch 41/70\n",
      "16458/16458 [==============================] - 0s - loss: 4520729.6376     \n",
      "Epoch 42/70\n",
      "16458/16458 [==============================] - 0s - loss: 4463487.6229     \n",
      "Epoch 43/70\n",
      "16458/16458 [==============================] - 0s - loss: 4462452.8360     \n",
      "Epoch 44/70\n",
      "16458/16458 [==============================] - 0s - loss: 4410724.1493     \n",
      "Epoch 45/70\n",
      "16458/16458 [==============================] - 0s - loss: 4375823.3685     \n",
      "Epoch 46/70\n",
      "16458/16458 [==============================] - 0s - loss: 4322361.9780     \n",
      "Epoch 47/70\n",
      "16458/16458 [==============================] - 0s - loss: 4295694.1739     \n",
      "Epoch 48/70\n",
      "16458/16458 [==============================] - 0s - loss: 4274123.1636     \n",
      "Epoch 49/70\n",
      "16458/16458 [==============================] - 0s - loss: 4218493.3685     \n",
      "Epoch 50/70\n",
      "16458/16458 [==============================] - 0s - loss: 4208680.3603     \n",
      "Epoch 51/70\n",
      "16458/16458 [==============================] - 0s - loss: 4162081.1689     \n",
      "Epoch 52/70\n",
      "16458/16458 [==============================] - 0s - loss: 4143819.5148     \n",
      "Epoch 53/70\n",
      "16458/16458 [==============================] - 0s - loss: 4104687.2592     \n",
      "Epoch 54/70\n",
      "16458/16458 [==============================] - 0s - loss: 4067682.4621     \n",
      "Epoch 55/70\n",
      "16458/16458 [==============================] - 0s - loss: 4050020.7832     \n",
      "Epoch 56/70\n",
      "16458/16458 [==============================] - 0s - loss: 4016431.1927     \n",
      "Epoch 57/70\n",
      "16458/16458 [==============================] - 0s - loss: 3965463.8274     \n",
      "Epoch 58/70\n",
      "16458/16458 [==============================] - 0s - loss: 3973689.1732     \n",
      "Epoch 59/70\n",
      "16458/16458 [==============================] - 0s - loss: 3921571.5458     \n",
      "Epoch 60/70\n",
      "16458/16458 [==============================] - 0s - loss: 3921571.7176     \n",
      "Epoch 61/70\n",
      "16458/16458 [==============================] - 0s - loss: 3880349.0907     \n",
      "Epoch 62/70\n",
      "16458/16458 [==============================] - 0s - loss: 3847976.6364     \n",
      "Epoch 63/70\n",
      "16458/16458 [==============================] - 0s - loss: 3849373.4312     \n",
      "Epoch 64/70\n",
      "16458/16458 [==============================] - 0s - loss: 3799230.5762     \n",
      "Epoch 65/70\n",
      "16458/16458 [==============================] - 0s - loss: 3791171.6122     \n",
      "Epoch 66/70\n",
      "16458/16458 [==============================] - 0s - loss: 3752708.9331     \n",
      "Epoch 67/70\n",
      "16458/16458 [==============================] - 0s - loss: 3724257.4428     \n",
      "Epoch 68/70\n",
      "16458/16458 [==============================] - 0s - loss: 3722813.5825     \n",
      "Epoch 69/70\n",
      "16458/16458 [==============================] - 0s - loss: 3677707.2503     \n",
      "Epoch 70/70\n",
      "16458/16458 [==============================] - 0s - loss: 3668450.7223     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa6930e4990>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(200, activation='relu', input_dim=vec_length))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(vec_length, activation='linear'))\n",
    "\n",
    "# For a mean squared error regression problem\n",
    "model.compile(optimizer='rmsprop', loss='mse')\n",
    "model.fit(mono_input, mono_output, epochs=70, batch_size=128)\n",
    "\n",
    "# print(np.max(mono_input))\n",
    "# print(np.min(mono_input))\n",
    "# print(np.max(mono_output))\n",
    "# print(np.min(mono_output))\n",
    "# print(type(mono_input[0,1]))\n",
    "\n",
    "# fi64 = np.finfo(np.float64)\n",
    "# print(fi64.min)\n",
    "# print(fi64.max)\n",
    "\n",
    "# test_a = np.array([1,2,3,4])\n",
    "# test_b = np.array([1,2,3,4,5])+8\n",
    "# test_list = [test_a, test_b]\n",
    "# test_vec = np.concatenate(test_list)\n",
    "# print(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16458, 276)\n",
      "(1, 3620760)\n",
      "coeffs shape: [44, 44, 69, 119]\n",
      "coeffs type: <type 'numpy.float32'>\n",
      "2\n",
      "reconstruction shape: (1810380, 2)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(mono_input)\n",
    "print(predictions.shape)\n",
    "\n",
    "reconstruction_array = []\n",
    "for i in range(predictions.shape[0]):\n",
    "    # don't forget to scale up again\n",
    "    coeffs = vector_to_list(predictions[i,:]) # *100000\n",
    "    rec_arr = np.array([pywt.waverec(coeffs, wavetype)]).astype('int16')\n",
    "    reconstruction_array.append(rec_arr)\n",
    "\n",
    "reconstruction_array = np.concatenate(reconstruction_array,axis=1)\n",
    "print(reconstruction_array.shape)\n",
    "# write_array = np.reshape(reconstruction_array, (-1,2))\n",
    "rec_split = np.split(reconstruction_array.T, 2)\n",
    "print(\"coeffs shape: \" + str([len(j) for j in coeffs]))\n",
    "print(\"coeffs type: \" + str(type(coeffs[0][0])))\n",
    "print(len(rec_split))\n",
    "\n",
    "write_array = np.concatenate((rec_split[0], rec_split[1]),axis=1)\n",
    "print('reconstruction shape: ' + str(write_array.shape))\n",
    "\n",
    "# output wav for auditory test\n",
    "wavfile.write('output/recons_network1.wav', input_rate, write_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now for the second (LSTM) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "95000*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_down(data):\n",
    "    # -95000, 95000 just fits over the max and min\n",
    "    return (data/190000.0)+0.5\n",
    "\n",
    "def scale_up(data):\n",
    "#     print(np.min(data))\n",
    "    return (data-0.5)*190000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0227254395685\n",
      "0.962889479605\n",
      "('nb sequences:', 16418)\n",
      "(16418, 276)\n",
      "(16418, 40, 276)\n",
      "<type 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "# pre-process into sequences\n",
    "# first we need to scale (lstm doesn't like huge inputs)\n",
    "scaled_in = scale_down(mono_input)\n",
    "scaled_out = scale_down(mono_output)\n",
    "\n",
    "print(np.min(scaled_out))\n",
    "print(np.max(scaled_out))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 1\n",
    "vec_sequences = []\n",
    "next_vecs = []\n",
    "for i in range(0, len(scaled_in) - maxlen, step):\n",
    "    vec_sequences.append(scaled_in[i: i + maxlen])\n",
    "    next_vecs.append(scaled_out[i + maxlen])\n",
    "#     next_vecs.append(mono_output[i + maxlen])\n",
    "vec_sequences = np.array(vec_sequences)\n",
    "next_vecs = np.array(next_vecs)\n",
    "print('nb sequences:', len(vec_sequences))\n",
    "# print(next_vecs[0].shape)\n",
    "# print(vec_sequences[0].shape)\n",
    "print(next_vecs.shape)\n",
    "print(vec_sequences.shape)\n",
    "print(type(next_vecs[0,0]))\n",
    "\n",
    "# x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "# y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "16418/16418 [==============================] - 10s - loss: 0.0812    \n",
      "Epoch 2/15\n",
      "16418/16418 [==============================] - 10s - loss: 0.0708    \n",
      "Epoch 3/15\n",
      "16418/16418 [==============================] - 10s - loss: 0.0680    \n",
      "Epoch 4/15\n",
      "16418/16418 [==============================] - 10s - loss: 0.0662    \n",
      "Epoch 5/15\n",
      "16418/16418 [==============================] - 10s - loss: 0.0659    \n",
      "Epoch 6/15\n",
      "16418/16418 [==============================] - 10s - loss: 0.0650    \n",
      "Epoch 7/15\n",
      "16418/16418 [==============================] - 10s - loss: 0.0649    \n",
      "Epoch 8/15\n",
      "16418/16418 [==============================] - 10s - loss: 0.0642    \n",
      "Epoch 9/15\n",
      "16418/16418 [==============================] - 10s - loss: 0.0630    \n",
      "Epoch 10/15\n",
      "16418/16418 [==============================] - 10s - loss: 0.0623    \n",
      "Epoch 11/15\n",
      "16418/16418 [==============================] - 10s - loss: 0.0619    \n",
      "Epoch 12/15\n",
      "16418/16418 [==============================] - 10s - loss: 0.0619    \n",
      "Epoch 13/15\n",
      "16418/16418 [==============================] - 10s - loss: 0.0618    \n",
      "Epoch 14/15\n",
      "16418/16418 [==============================] - 10s - loss: 0.0618    \n",
      "Epoch 15/15\n",
      "16418/16418 [==============================] - 10s - loss: 0.0618    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa5f5cae850>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Define an input sequence and process it.\n",
    "# encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "# encoder = LSTM(latent_dim, return_state=True)\n",
    "# encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# # We discard `encoder_outputs` and only keep the states.\n",
    "# encoder_states = [state_h, state_c]\n",
    "\n",
    "# # Set up the decoder, using `encoder_states` as initial state.\n",
    "# decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# # We set up our decoder to return full output sequences,\n",
    "# # and to return internal states as well. We don't use the \n",
    "# # return states in the training model, but we will use them in inference.\n",
    "# decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "# decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "#                                      initial_state=encoder_states)\n",
    "# decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "# decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# # Define the model that will turn\n",
    "# # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "# model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(300, input_shape=(maxlen, vec_length)))\n",
    "\n",
    "lstm_model.add(Dense(200, activation='relu', input_dim=vec_length))\n",
    "lstm_model.add(Dense(200, activation='relu'))\n",
    "lstm_model.add(Dense(vec_length, activation='relu'))\n",
    "\n",
    "# For a mean squared error regression problem\n",
    "lstm_model.compile(optimizer='rmsprop', loss='mse')\n",
    "\n",
    "# lstm_model.add(Dense(vec_length))\n",
    "# # lstm_model.add(Activation('softmax'))\n",
    "# lstm_model.add(Activation(\"linear\"))\n",
    "\n",
    "\n",
    "# # lstm_model.add(Activation(\"sigmoid\")) \n",
    "\n",
    "# optimizer = RMSprop(lr=0.1)\n",
    "# lstm_model.compile(loss='mse', optimizer=optimizer)\n",
    "\n",
    "lstm_model.fit(vec_sequences, next_vecs, batch_size=128, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.00000000e+03  -2.34235000e+05   5.46660000e+04  -1.23000000e+02\n",
      "    2.22000000e+02]\n",
      " [  1.00000000e+03  -2.34235000e+05   5.46660000e+04  -1.23000000e+02\n",
      "    2.22000000e+02]]\n"
     ]
    }
   ],
   "source": [
    "e_test = np.array([[1000,-234235,54666,-123,222],[1000,-234235,54666,-123,222]])\n",
    "low_e = scale_down(e_test)\n",
    "high_e = scale_up(low_e)\n",
    "print(high_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--RAW PREDICTION DATA--\n",
      "(16418, 276)\n",
      "min, max\n",
      "(0.0, 0.50962889)\n",
      "--TARGET DATA--\n",
      "(16418, 276)\n",
      "min, max\n",
      "(0.022725439568491657, 0.96288947960481064)\n",
      "--SCALED UP PREDICTION--\n",
      "(16418, 276)\n",
      "min, max\n",
      "(-95000.0, 1829.4895)\n",
      "--RAW TARGET--\n",
      "(16458, 276)\n",
      "min, max\n",
      "(-90682.166481986584, 87949.001124914023)\n",
      "--SCALED UP TARGET--\n",
      "(16418, 276)\n",
      "min, max\n",
      "(-90682.166481986584, 87949.001124914023)\n",
      "reconstruction done\n",
      "coeffs shape: [44, 44, 69, 119]\n",
      "coeffs type: <type 'numpy.float32'>\n",
      "2\n",
      "reconstruction shape: (1805980, 2)\n"
     ]
    }
   ],
   "source": [
    "predictions = lstm_model.predict(vec_sequences)\n",
    "print(\"--RAW PREDICTION DATA--\")\n",
    "print(predictions.shape)\n",
    "print(\"min, max\")\n",
    "print(np.min(predictions),np.max(predictions))\n",
    "\n",
    "print(\"--TARGET DATA--\")\n",
    "print(next_vecs.shape)\n",
    "print(\"min, max\")\n",
    "print(np.min(next_vecs),np.max(next_vecs))\n",
    "\n",
    "scaled_up_predictions = scale_up(predictions)\n",
    "print(\"--SCALED UP PREDICTION--\")\n",
    "print(scaled_up_predictions.shape)\n",
    "print(\"min, max\")\n",
    "print(np.min(scaled_up_predictions),np.max(scaled_up_predictions))\n",
    "\n",
    "print(\"--RAW TARGET--\")\n",
    "print(mono_output.shape)\n",
    "print(\"min, max\")\n",
    "print(np.min(mono_output),np.max(mono_output))\n",
    "\n",
    "scaled_up_target = scale_up(next_vecs)\n",
    "print(\"--SCALED UP TARGET--\")\n",
    "print(scaled_up_target.shape)\n",
    "print(\"min, max\")\n",
    "print(np.min(scaled_up_target),np.max(scaled_up_target))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "reconstruction_array = []\n",
    "for i in range(predictions.shape[0]):\n",
    "    # don't forget to scale up again\n",
    "#     coeffs = vector_to_list(np.array(scale_up(predictions[i,:]),dtype=np.float64))\n",
    "    coeffs = vector_to_list(sclaed_up_predictions[i,:])\n",
    "    rec_arr = np.array([pywt.waverec(coeffs, wavetype)]).astype('int16')\n",
    "    reconstruction_array.append(rec_arr)\n",
    "\n",
    "print(\"reconstruction done\")\n",
    "print(\"coeffs shape: \" + str([len(j) for j in coeffs]))\n",
    "print(\"coeffs type: \" + str(type(coeffs[0][0])))\n",
    "\n",
    "# scale it up before writing\n",
    "reconstruction_array = np.concatenate(reconstruction_array,axis=1)\n",
    "# scaled_up_out = scale_up(reconstruction_array)\n",
    "# print(\"max, min for original output\")\n",
    "# print(\"max, min for scaled up recon\")\n",
    "# print(np.max(coeffs[0]))\n",
    "# print(np.min(coeffs[0]))\n",
    "# print(reconstruction_array.shape)\n",
    "# print(\"max, min for original output\")\n",
    "# print(np.max(mono_output))\n",
    "# print(np.min(mono_output))\n",
    "# print(scaled_up_out.shape)\n",
    "# write_array = np.reshape(reconstruction_array, (-1,2))\n",
    "rec_split = np.split(reconstruction_array.T, 2)\n",
    "print(len(rec_split))\n",
    "\n",
    "write_array = np.concatenate((rec_split[0], rec_split[1]),axis=1)\n",
    "print('reconstruction shape: ' + str(write_array.shape))\n",
    "\n",
    "# output wav for auditory test\n",
    "wavfile.write('output/recons_network2.wav', input_rate, write_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.49083388, 0.49998259269456513)\n",
      "(0.49014306, 0.50001232054436817)\n",
      "(0.49065757, 0.5000209328511025)\n",
      "(0.49058855, 0.50001488950860762)\n",
      "(0.48991048, 0.50001346089001653)\n",
      "(0.49096224, 0.50000368411431551)\n",
      "(0.49101716, 0.50001706517046862)\n",
      "(0.48992157, 0.50001358466243806)\n",
      "(0.48961061, 0.49997704666606835)\n",
      "(0.49075043, 0.49999569294121593)\n",
      "(0.48955449, 0.50000156172726429)\n",
      "(0.49045569, 0.50002705724033902)\n",
      "(0.49036357, 0.49997686044744033)\n",
      "(0.49035597, 0.49999624832033479)\n",
      "(0.48974282, 0.50000880581480334)\n",
      "(0.49089664, 0.50001774595722626)\n",
      "(0.48977643, 0.49998900824396575)\n",
      "(0.49041963, 0.50002394174554921)\n",
      "(0.49065423, 0.50000331564987543)\n",
      "(0.48976395, 0.49999149466988901)\n",
      "(0.49084002, 0.50000439142194331)\n",
      "(0.4911465, 0.49996972578703808)\n",
      "(0.49071544, 0.49998242931699227)\n",
      "(0.48989797, 0.49999722009805697)\n",
      "(0.48986825, 0.49997012119216966)\n",
      "(0.49077523, 0.49998880444316951)\n",
      "(0.49032211, 0.50001444482778079)\n",
      "(0.49044919, 0.50000588558443015)\n",
      "(0.49013022, 0.50000658255666908)\n",
      "(0.49043936, 0.50000758847213678)\n",
      "(0.48998606, 0.49999263180861436)\n",
      "(0.48969564, 0.50000730029920726)\n",
      "(0.48982251, 0.50000709915666053)\n",
      "(0.48992896, 0.50000816323082797)\n",
      "(0.49034604, 0.49998896817962124)\n",
      "(0.49044919, 0.50001017838355988)\n",
      "(0.48955363, 0.49999959827348328)\n",
      "(0.49007246, 0.50000824794264065)\n",
      "(0.49059045, 0.50001131843306024)\n",
      "(0.49036986, 0.50001497605086009)\n",
      "(0.48978913, 0.50001342869273713)\n",
      "(0.49022573, 0.50001391610937684)\n",
      "(0.48944029, 0.49998985645406663)\n",
      "(0.48946303, 0.49999437154258314)\n",
      "(0.48976517, 0.49999750869181286)\n",
      "(0.49065998, 0.50001083535181734)\n",
      "(0.48999816, 0.5000111022341388)\n",
      "(0.49063122, 0.49997888119949413)\n",
      "(0.49106395, 0.49999521544952769)\n",
      "(0.4906829, 0.49999751240247703)\n"
     ]
    }
   ],
   "source": [
    "for i in range(150,200):\n",
    "    print(predictions[1003,i], next_vecs[1003,i])\n",
    "#     print(next_vecs[10000,i])\n",
    "# print(predictions[10000,90:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"predictions shape, max, min, type, example\")\n",
    "print(predictions.shape)\n",
    "print(np.max(predictions))\n",
    "print(np.min(predictions))\n",
    "print(type(predictions[0,0]))\n",
    "print(predictions[0,0])\n",
    "\n",
    "print(\"scaled down output shape, max, min, type, example\")\n",
    "print(next_vecs.shape)\n",
    "print(np.max(next_vecs))\n",
    "print(np.min(next_vecs))\n",
    "print(type(next_vecs[0,0]))\n",
    "print(next_vecs[0,0])\n",
    "\n",
    "# reconstruct target output for bug\n",
    "\n",
    "\n",
    "reconstruction_array = []\n",
    "for i in range(predictions.shape[0]):\n",
    "    # don't forget to scale up again\n",
    "    coeffs = vector_to_list(scale_up(next_vecs[i,:]))\n",
    "    rec_arr = np.array([pywt.waverec(coeffs, wavetype)]).astype('int16')\n",
    "    reconstruction_array.append(rec_arr)\n",
    "\n",
    "print(\"reconstruction done\")\n",
    "print(\"coeffs shape: \" + str([len(j) for j in coeffs]))\n",
    "print(\"coeffs type: \" + str(type(coeffs[0][0])))\n",
    "\n",
    "# scale it up before writing\n",
    "reconstruction_array = np.concatenate(reconstruction_array,axis=1)\n",
    "\n",
    "# write_array = np.reshape(reconstruction_array, (-1,2))\n",
    "rec_split = np.split(reconstruction_array.T, 2)\n",
    "\n",
    "\n",
    "write_array = np.concatenate((rec_split[0], rec_split[1]),axis=1)\n",
    "print('reconstruction shape: ' + str(write_array.shape))\n",
    "\n",
    "# output wav for auditory test\n",
    "wavfile.write('output/recons_target_lstm.wav', input_rate, write_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEFTOVERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = []\n",
    "# a.append('asdsd')\n",
    "# a.append('adfgbsdfgbdfg')\n",
    "# a\n",
    "range(1,6,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPRECATED\n",
    "# reshapes total sequence into batches\n",
    "def get_batches(batch_size, sequence_length, input_sequence, output_sequence):\n",
    "    batch_amount = int(math.floor(total_samples/float(batch_size*sequence_length)))\n",
    "    input_batches = []\n",
    "    output_batches = []\n",
    "    print('creating ' + str(batch_amount) + ' batches')\n",
    "    for batch_index in range(1, batch_amount + 1):\n",
    "        print(batch_index)\n",
    "        for sequence_index in range(0,sequence_length*batch_size,sequence_length):\n",
    "            print(sequence_index)\n",
    "            sequence = input_sequence[sequence_index:sequence_index+sequence_length,:]\n",
    "            \n",
    "    \n",
    "# https://keras.io/layers/wrappers/\n",
    "\n",
    "# Consider a batch of 32 samples, where each sample is a sequence of 10 vectors of 16 dimensions. \n",
    "# The batch input shape of the layer is then (32, 10, 16), and the input_shape, not including \n",
    "# the samples dimension, is (10, 16)\n",
    "\n",
    "# batch_size = 32\n",
    "# sequence_length = 20   # no. of vectors in each sequence\n",
    "# vector_length = input_matrix.shape[1]\n",
    "# total_samples = input_matrix.shape[0]\n",
    "\n",
    "\n",
    "# input_batches, output_batches = get_batches(batch_size, sequence_length, input_matrix, output_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# build model\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(1, input_shape=(timesteps, data_dim), return_sequences=True))\n",
    "# model.add(TimeDistributed(Dense(vector_length), input_shape=(sequence_length, vector_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def group_list(l, group_size):\n",
    "#     \"\"\"\n",
    "#     :param l:           list\n",
    "#     :param group_size:  size of each group\n",
    "#     :return:            Yields successive group-sized lists from l.\n",
    "#     \"\"\"\n",
    "# #     res_arr = \n",
    "#     for i in xrange(0, len(l), group_size):\n",
    "#         yield l[i:i+group_size,:]\n",
    "\n",
    "# def get_np_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leftovers\n"
     ]
    }
   ],
   "source": [
    "print('leftovers')\n",
    "\n",
    "# max_features = 2124\n",
    "# maxlen = 80  # cut texts after this number of words (among top max_features most common words)\n",
    "# batch_size = 32\n",
    "# lstm_units = 250\n",
    "\n",
    "# # output_res = output_matrix #.reshape((-1, 1))\n",
    "\n",
    "# input_batches = group_list(input_matrix, batch_size)\n",
    "# output_batches = group_list(output_matrix, batch_size)\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(LSTM(max_features, input_dim=max_features))\n",
    "# model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "# model.fit(input_batches,output_batches, nb_epoch=10)\n",
    "\n",
    "\n",
    "\n",
    "# model.add(Embedding(max_features, lstm_units))\n",
    "# model.add(LSTM(lstm_units, dropout=0.2, recurrent_dropout=0.2, input_shape=(max_features, )))\n",
    "# model.add(Dense(max_features, activation='sigmoid'))\n",
    "\n",
    "# # try using different optimizers and different optimizer configs\n",
    "# model.compile(loss='sparse_categorical_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# print('Train...')\n",
    "# model.fit(input_matrix, output_res,\n",
    "# #           batch_size=batch_size,\n",
    "#           epochs=15,\n",
    "#           validation_data=(input_matrix, output_res))\n",
    "# score, acc = model.evaluate(input_matrix, output_res) #, batch_size=batch_size)\n",
    "# print('Test score:', score)\n",
    "# print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
