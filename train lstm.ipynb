{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pywt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.io.wavfile as wavfile\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_rate, input_signal = wavfile.read('data/1clean_Selection.wav')\n",
    "output_rate, output_signal = wavfile.read('data/1Selection.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing out pywt functions and reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max wave level decomposition: 16\n",
      "input signal shape: (1810432, 2)\n",
      "reconstruction shape: (1810432, 2)\n",
      "['bior1.1', 'bior1.3', 'bior1.5', 'bior2.2', 'bior2.4', 'bior2.6', 'bior2.8', 'bior3.1', 'bior3.3', 'bior3.5', 'bior3.7', 'bior3.9', 'bior4.4', 'bior5.5', 'bior6.8', 'cgau1', 'cgau2', 'cgau3', 'cgau4', 'cgau5', 'cgau6', 'cgau7', 'cgau8', 'cmor', 'coif1', 'coif2', 'coif3', 'coif4', 'coif5', 'coif6', 'coif7', 'coif8', 'coif9', 'coif10', 'coif11', 'coif12', 'coif13', 'coif14', 'coif15', 'coif16', 'coif17', 'db1', 'db2', 'db3', 'db4', 'db5', 'db6', 'db7', 'db8', 'db9', 'db10', 'db11', 'db12', 'db13', 'db14', 'db15', 'db16', 'db17', 'db18', 'db19', 'db20', 'db21', 'db22', 'db23', 'db24', 'db25', 'db26', 'db27', 'db28', 'db29', 'db30', 'db31', 'db32', 'db33', 'db34', 'db35', 'db36', 'db37', 'db38', 'dmey', 'fbsp', 'gaus1', 'gaus2', 'gaus3', 'gaus4', 'gaus5', 'gaus6', 'gaus7', 'gaus8', 'haar', 'mexh', 'morl', 'rbio1.1', 'rbio1.3', 'rbio1.5', 'rbio2.2', 'rbio2.4', 'rbio2.6', 'rbio2.8', 'rbio3.1', 'rbio3.3', 'rbio3.5', 'rbio3.7', 'rbio3.9', 'rbio4.4', 'rbio5.5', 'rbio6.8', 'shan', 'sym2', 'sym3', 'sym4', 'sym5', 'sym6', 'sym7', 'sym8', 'sym9', 'sym10', 'sym11', 'sym12', 'sym13', 'sym14', 'sym15', 'sym16', 'sym17', 'sym18', 'sym19', 'sym20']\n"
     ]
    }
   ],
   "source": [
    "# some settings:\n",
    "wavetype = 'db10'\n",
    "# wavelevel = 15\n",
    "\n",
    "w = pywt.Wavelet(wavetype)\n",
    "wavelevel = pywt.dwt_max_level(data_len=input_signal.shape[0], filter_len=w.dec_len)\n",
    "\n",
    "# set a little lower:\n",
    "# wavelevel = 1\n",
    "print(\"Max wave level decomposition: \" + str(wavelevel))\n",
    "\n",
    "# these are floats, original is int16\n",
    "input_coeffs1 = pywt.wavedec(input_signal[:,0].T, wavetype, level=wavelevel)\n",
    "input_coeffs2 = pywt.wavedec(input_signal[:,1].T, wavetype, level=wavelevel)\n",
    "# output_coeffs1 = pywt.wavedec(output_signal[:,0].T, wavetype, level=wavelevel)\n",
    "# output_coeffs2 = pywt.wavedec(output_signal[:,1].T, wavetype, level=wavelevel)\n",
    "print(\"input signal shape: \" + str(input_signal.shape))\n",
    "\n",
    "# reconstruction for left and right channel\n",
    "recons1 = np.array([pywt.waverec(input_coeffs1, wavetype)]).astype('int16')\n",
    "recons2 = np.array([pywt.waverec(input_coeffs2, wavetype)]).astype('int16')\n",
    "\n",
    "# print(recons1.shape)\n",
    "\n",
    "write_array = np.concatenate((recons1,recons2),axis=0).T\n",
    "print('reconstruction shape: ' + str(write_array.shape))\n",
    "\n",
    "# output wav for auditory test\n",
    "wavfile.write('output/recons.wav', input_rate, write_array)\n",
    "\n",
    "# get available wavelets\n",
    "print(pywt.wavelist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0 -1 -2 -2 -3 -2 -1 -1]\n",
      "[ 0  0  0 -1 -1 -1 -2 -1  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(input_signal[:10,0].T)\n",
    "print(recons1[0,:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare data for tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cut it into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet_to_vector(input_raw, output_raw, chunk_size, wavelet_level, wavelet_type):\n",
    "    current_set = 'input'\n",
    "    \n",
    "    w = pywt.Wavelet(wavelet_type)\n",
    "    max_level = pywt.dwt_max_level(data_len=chunk_size, filter_len=w.dec_len)\n",
    "    if wavelet_level > max_level:\n",
    "        print('wavelet level too high. set to max level: ' + str(max_level))\n",
    "        wavelet_level = max_level\n",
    "    \n",
    "    # short hacky loop\n",
    "    while True:\n",
    "        # select the correct set\n",
    "        if current_set == 'input':\n",
    "            data = input_raw\n",
    "            amount_of_chunks = int(math.floor(data.shape[0]/chunk_size))\n",
    "            input_list = []\n",
    "        else:\n",
    "            data = output_raw\n",
    "            amount_of_chunks = int(math.floor(data.shape[0]/chunk_size))\n",
    "            output_list = []\n",
    "\n",
    "        \n",
    "        index_range = (np.arange(amount_of_chunks) * chunk_size)\n",
    "        indp = chunk_size - 1\n",
    "        # for all chunks do this:\n",
    "        for ind in index_range:\n",
    "#             print(ind)\n",
    "            sample1 = data[ind:ind+indp,0].T\n",
    "            sample2 = data[ind:ind+indp,0].T\n",
    "            coeffs1 = pywt.wavedec(sample1, wavelet_type, level=wavelet_level)\n",
    "            coeffs2 = pywt.wavedec(sample2, wavelet_type, level=wavelet_level)\n",
    "            unfolded1 = np.array([item for sublist in coeffs1 for item in sublist])\n",
    "            unfolded2 = np.array([item for sublist in coeffs1 for item in sublist])\n",
    "            vector = np.concatenate((unfolded1,unfolded2),axis=0)\n",
    "            \n",
    "            if current_set == 'input':\n",
    "                input_list.append(vector)\n",
    "            else:\n",
    "                output_list.append(vector)\n",
    "#             unf_arr = np.array(unfolded1)\n",
    "#             print(unf_arr.shape)\n",
    "#             print(len(unfolded))\n",
    "            \n",
    "            # for all coeff levels:\n",
    "#             for i in range(len(coeffs1)):\n",
    "#                 print(i)\n",
    "            \n",
    "        \n",
    "        \n",
    "        if current_set == 'output':\n",
    "            break\n",
    "        current_set = 'output'\n",
    "\n",
    "    # convert lists to arrays\n",
    "    input_arr = np.array(input_list)\n",
    "    output_arr = np.array(output_list)\n",
    "    \n",
    "    # return level sizes for reconstruction\n",
    "    level_sizes = []\n",
    "    for cf in coeffs1:\n",
    "        level_sizes.append(cf.shape[0])\n",
    "    return [input_arr, output_arr, level_sizes]\n",
    "# input_coeffs1[16].shape\n",
    "\n",
    "# rows=samples, cols=dim\n",
    "[input_matrix, output_matrix, level_sizes] = wavelet_to_vector(input_signal, output_signal, 1024, 6, 'db4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1768, 2124)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([4,5,7,4])\n",
    "b = np.array([6,2,0,9])\n",
    "# np.array([a, b])\n",
    "# np.concatenate((a.T,b.T),axis=1)\n",
    "# np.zeros([5,2])\n",
    "# for cf in coef_test:\n",
    "#     print(cf.shape)\n",
    "# print(level_sizes)\n",
    "np.array([a,b])\n",
    "c = []\n",
    "c.append(a)\n",
    "c.append(b)\n",
    "# np.array(c)\n",
    "# a + b\n",
    "# print(a.shape)\n",
    "# np.concatenate((a,b),axis=0)\n",
    "input_matrix.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
