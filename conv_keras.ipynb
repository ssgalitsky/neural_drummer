{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Install the plaidml backend\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import plaidml.keras\n",
    "plaidml.keras.install_backend()\n",
    "# import keras\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Convolution1D, Dense, MaxPooling1D, Flatten\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simple single timeseries vector prediction\n",
      "\n",
      "\n",
      "Timeseries (1000 samples by 1 series):\n",
      " [[  0]\n",
      " [  1]\n",
      " [  2]\n",
      " ..., \n",
      " [997]\n",
      " [998]\n",
      " [999]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", input_shape=(50, 1), filters=4, kernel_size=5)`\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", kernel_size=5, filters=4)`\n",
      "INFO:plaidml:Initializing device geforce_gtx_1060_6gb.0: \"GeForce GTX 1060 6GB\", vendor \"NVIDIA Corporation\"\n",
      "INFO:plaidml:Opening device \"geforce_gtx_1060_6gb.0\": \"NVIDIA Corporation GeForce GTX 1060 6GB\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model with input size (None, 50, 1), output size (None, 1), 4 conv filters of length 5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 46, 4)             24        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 23, 4)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 19, 4)             84        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 9, 4)              0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 37        \n",
      "=================================================================\n",
      "Total params: 145\n",
      "Trainable params: 145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "Input features:\n",
      "[[[  0]\n",
      "  [  1]\n",
      "  [  2]\n",
      "  ..., \n",
      "  [ 47]\n",
      "  [ 48]\n",
      "  [ 49]]\n",
      "\n",
      " [[  1]\n",
      "  [  2]\n",
      "  [  3]\n",
      "  ..., \n",
      "  [ 48]\n",
      "  [ 49]\n",
      "  [ 50]]\n",
      "\n",
      " [[  2]\n",
      "  [  3]\n",
      "  [  4]\n",
      "  ..., \n",
      "  [ 49]\n",
      "  [ 50]\n",
      "  [ 51]]\n",
      "\n",
      " ..., \n",
      " [[947]\n",
      "  [948]\n",
      "  [949]\n",
      "  ..., \n",
      "  [994]\n",
      "  [995]\n",
      "  [996]]\n",
      "\n",
      " [[948]\n",
      "  [949]\n",
      "  [950]\n",
      "  ..., \n",
      "  [995]\n",
      "  [996]\n",
      "  [997]]\n",
      "\n",
      " [[949]\n",
      "  [950]\n",
      "  [951]\n",
      "  ..., \n",
      "  [996]\n",
      "  [997]\n",
      "  [998]]]\n",
      "\n",
      "\n",
      "Output labels:\n",
      "[[ 50]\n",
      " [ 51]\n",
      " [ 52]\n",
      " ..., \n",
      " [997]\n",
      " [998]\n",
      " [999]]\n",
      "\n",
      "\n",
      "Query vector:\n",
      "[[[950]\n",
      "  [951]\n",
      "  [952]\n",
      "  ..., \n",
      "  [997]\n",
      "  [998]\n",
      "  [999]]]\n",
      "Train on 940 samples, validate on 10 samples\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "940/940 [==============================] - 3s - loss: 27569.2542 - mean_absolute_error: 65.3385 - val_loss: 197.5113 - val_mean_absolute_error: 14.0535\n",
      "Epoch 2/25\n",
      "940/940 [==============================] - 2s - loss: 87.0066 - mean_absolute_error: 7.7919 - val_loss: 37.4592 - val_mean_absolute_error: 6.1199\n",
      "Epoch 3/25\n",
      "940/940 [==============================] - 2s - loss: 85.5402 - mean_absolute_error: 7.7380 - val_loss: 145.4774 - val_mean_absolute_error: 12.0611\n",
      "Epoch 4/25\n",
      "940/940 [==============================] - 2s - loss: 82.2643 - mean_absolute_error: 7.5221 - val_loss: 103.5977 - val_mean_absolute_error: 10.1779\n",
      "Epoch 5/25\n",
      "940/940 [==============================] - 2s - loss: 82.7080 - mean_absolute_error: 7.5878 - val_loss: 150.0401 - val_mean_absolute_error: 12.2488\n",
      "Epoch 6/25\n",
      "940/940 [==============================] - 2s - loss: 78.2688 - mean_absolute_error: 7.4242 - val_loss: 60.3283 - val_mean_absolute_error: 7.7668\n",
      "Epoch 7/25\n",
      "940/940 [==============================] - 2s - loss: 74.2161 - mean_absolute_error: 7.1925 - val_loss: 66.8749 - val_mean_absolute_error: 8.1774\n",
      "Epoch 8/25\n",
      "940/940 [==============================] - 2s - loss: 73.0114 - mean_absolute_error: 7.1681 - val_loss: 162.6141 - val_mean_absolute_error: 12.7517\n",
      "Epoch 9/25\n",
      "940/940 [==============================] - 2s - loss: 69.9038 - mean_absolute_error: 7.0987 - val_loss: 123.9563 - val_mean_absolute_error: 11.1333\n",
      "Epoch 10/25\n",
      "940/940 [==============================] - 2s - loss: 63.1212 - mean_absolute_error: 6.7122 - val_loss: 0.6287 - val_mean_absolute_error: 0.7916\n",
      "Epoch 11/25\n",
      "940/940 [==============================] - 2s - loss: 60.9675 - mean_absolute_error: 6.5818 - val_loss: 21.1593 - val_mean_absolute_error: 4.5996\n",
      "Epoch 12/25\n",
      "940/940 [==============================] - 2s - loss: 50.6167 - mean_absolute_error: 5.9974 - val_loss: 260.7135 - val_mean_absolute_error: 16.1464\n",
      "Epoch 13/25\n",
      "940/940 [==============================] - 2s - loss: 46.3132 - mean_absolute_error: 5.8239 - val_loss: 96.1962 - val_mean_absolute_error: 9.8078\n",
      "Epoch 14/25\n",
      "940/940 [==============================] - 2s - loss: 40.4662 - mean_absolute_error: 5.3729 - val_loss: 1.5883 - val_mean_absolute_error: 1.2597\n",
      "Epoch 15/25\n",
      "940/940 [==============================] - 2s - loss: 34.5045 - mean_absolute_error: 4.9794 - val_loss: 40.1023 - val_mean_absolute_error: 6.3325\n",
      "Epoch 16/25\n",
      "940/940 [==============================] - 2s - loss: 30.9896 - mean_absolute_error: 4.6191 - val_loss: 1.9208 - val_mean_absolute_error: 1.3856\n",
      "Epoch 17/25\n",
      "940/940 [==============================] - 2s - loss: 25.7891 - mean_absolute_error: 4.2609 - val_loss: 0.0764 - val_mean_absolute_error: 0.2752\n",
      "Epoch 18/25\n",
      "940/940 [==============================] - 2s - loss: 19.1922 - mean_absolute_error: 3.7281 - val_loss: 12.8122 - val_mean_absolute_error: 3.5793\n",
      "Epoch 19/25\n",
      "940/940 [==============================] - 2s - loss: 22.9011 - mean_absolute_error: 3.8882 - val_loss: 1.0644 - val_mean_absolute_error: 1.0315\n",
      "Epoch 20/25\n",
      "940/940 [==============================] - 2s - loss: 16.4810 - mean_absolute_error: 3.4213 - val_loss: 71.1837 - val_mean_absolute_error: 8.4369\n",
      "Epoch 21/25\n",
      "940/940 [==============================] - 2s - loss: 11.5893 - mean_absolute_error: 2.8839 - val_loss: 0.1474 - val_mean_absolute_error: 0.3836\n",
      "Epoch 22/25\n",
      "940/940 [==============================] - 2s - loss: 9.4380 - mean_absolute_error: 2.6121 - val_loss: 56.5836 - val_mean_absolute_error: 7.5221\n",
      "Epoch 23/25\n",
      "940/940 [==============================] - 2s - loss: 11.2267 - mean_absolute_error: 2.7007 - val_loss: 0.3238 - val_mean_absolute_error: 0.5690\n",
      "Epoch 24/25\n",
      "940/940 [==============================] - 2s - loss: 11.3417 - mean_absolute_error: 2.5898 - val_loss: 6.1913 - val_mean_absolute_error: 2.4882\n",
      "Epoch 25/25\n",
      "940/940 [==============================] - 2s - loss: 5.4646 - mean_absolute_error: 1.8043 - val_loss: 27.4256 - val_mean_absolute_error: 5.2369\n",
      "\n",
      "\n",
      "actual\tpredicted\n",
      "990\t984.774\n",
      "991\t985.772\n",
      "992\t986.769\n",
      "993\t987.767\n",
      "994\t988.764\n",
      "995\t989.762\n",
      "996\t990.759\n",
      "997\t991.757\n",
      "998\t992.754\n",
      "999\t993.752\n",
      "next\t994.749084473\n",
      "\n",
      "Multiple-input, multiple-output prediction\n",
      "\n",
      "\n",
      "Timeseries (1000 samples by 2 series):\n",
      " [[   0    0]\n",
      " [   1   -1]\n",
      " [   2   -2]\n",
      " ..., \n",
      " [ 997 -997]\n",
      " [ 998 -998]\n",
      " [ 999 -999]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", input_shape=(50, 2), filters=4, kernel_size=5)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model with input size (None, 50, 2), output size (None, 2), 4 conv filters of length 5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 46, 4)             44        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 23, 4)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 19, 4)             84        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 9, 4)              0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 74        \n",
      "=================================================================\n",
      "Total params: 202\n",
      "Trainable params: 202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "Input features:\n",
      "[[[   0    0]\n",
      "  [   1   -1]\n",
      "  [   2   -2]\n",
      "  ..., \n",
      "  [  47  -47]\n",
      "  [  48  -48]\n",
      "  [  49  -49]]\n",
      "\n",
      " [[   1   -1]\n",
      "  [   2   -2]\n",
      "  [   3   -3]\n",
      "  ..., \n",
      "  [  48  -48]\n",
      "  [  49  -49]\n",
      "  [  50  -50]]\n",
      "\n",
      " [[   2   -2]\n",
      "  [   3   -3]\n",
      "  [   4   -4]\n",
      "  ..., \n",
      "  [  49  -49]\n",
      "  [  50  -50]\n",
      "  [  51  -51]]\n",
      "\n",
      " ..., \n",
      " [[ 947 -947]\n",
      "  [ 948 -948]\n",
      "  [ 949 -949]\n",
      "  ..., \n",
      "  [ 994 -994]\n",
      "  [ 995 -995]\n",
      "  [ 996 -996]]\n",
      "\n",
      " [[ 948 -948]\n",
      "  [ 949 -949]\n",
      "  [ 950 -950]\n",
      "  ..., \n",
      "  [ 995 -995]\n",
      "  [ 996 -996]\n",
      "  [ 997 -997]]\n",
      "\n",
      " [[ 949 -949]\n",
      "  [ 950 -950]\n",
      "  [ 951 -951]\n",
      "  ..., \n",
      "  [ 996 -996]\n",
      "  [ 997 -997]\n",
      "  [ 998 -998]]]\n",
      "\n",
      "\n",
      "Output labels:\n",
      "[[  50  -50]\n",
      " [  51  -51]\n",
      " [  52  -52]\n",
      " ..., \n",
      " [ 997 -997]\n",
      " [ 998 -998]\n",
      " [ 999 -999]]\n",
      "\n",
      "\n",
      "Query vector:\n",
      "[[[ 950 -950]\n",
      "  [ 951 -951]\n",
      "  [ 952 -952]\n",
      "  ..., \n",
      "  [ 997 -997]\n",
      "  [ 998 -998]\n",
      "  [ 999 -999]]]\n",
      "Train on 940 samples, validate on 10 samples\n",
      "Epoch 1/25\n",
      "940/940 [==============================] - 3s - loss: 341842.4102 - mean_absolute_error: 517.8747 - val_loss: 979503.2625 - val_mean_absolute_error: 989.6942\n",
      "Epoch 2/25\n",
      "940/940 [==============================] - 2s - loss: 332422.5667 - mean_absolute_error: 508.6304 - val_loss: 953382.7375 - val_mean_absolute_error: 976.4083\n",
      "Epoch 3/25\n",
      "940/940 [==============================] - 2s - loss: 315573.6256 - mean_absolute_error: 491.9800 - val_loss: 914340.8000 - val_mean_absolute_error: 956.2060\n",
      "Epoch 4/25\n",
      "940/940 [==============================] - 2s - loss: 293362.0875 - mean_absolute_error: 468.9002 - val_loss: 865778.6250 - val_mean_absolute_error: 930.4655\n",
      "Epoch 5/25\n",
      "940/940 [==============================] - 2s - loss: 268138.5802 - mean_absolute_error: 441.6593 - val_loss: 811401.2000 - val_mean_absolute_error: 900.7700\n",
      "Epoch 6/25\n",
      "940/940 [==============================] - 2s - loss: 241428.1818 - mean_absolute_error: 413.1694 - val_loss: 752914.6625 - val_mean_absolute_error: 867.6970\n",
      "Epoch 7/25\n",
      "940/940 [==============================] - 2s - loss: 214390.6793 - mean_absolute_error: 385.0020 - val_loss: 692133.1875 - val_mean_absolute_error: 831.9342\n",
      "Epoch 8/25\n",
      "940/940 [==============================] - 2s - loss: 188301.4035 - mean_absolute_error: 356.8800 - val_loss: 631467.7750 - val_mean_absolute_error: 794.6366\n",
      "Epoch 9/25\n",
      "940/940 [==============================] - 2s - loss: 164300.2418 - mean_absolute_error: 331.2238 - val_loss: 572818.9000 - val_mean_absolute_error: 756.8334\n",
      "Epoch 10/25\n",
      "940/940 [==============================] - 2s - loss: 142889.0175 - mean_absolute_error: 308.8685 - val_loss: 516731.0125 - val_mean_absolute_error: 718.8239\n",
      "Epoch 11/25\n",
      "940/940 [==============================] - 2s - loss: 124532.7347 - mean_absolute_error: 289.2948 - val_loss: 465248.6437 - val_mean_absolute_error: 682.0739\n",
      "Epoch 12/25\n",
      "940/940 [==============================] - 2s - loss: 109653.5535 - mean_absolute_error: 273.1566 - val_loss: 418787.8750 - val_mean_absolute_error: 647.1197\n",
      "Epoch 13/25\n",
      "940/940 [==============================] - 2s - loss: 98045.8047 - mean_absolute_error: 260.9729 - val_loss: 378466.2062 - val_mean_absolute_error: 615.1771\n",
      "Epoch 14/25\n",
      "940/940 [==============================] - 2s - loss: 89396.8932 - mean_absolute_error: 251.6806 - val_loss: 343566.5000 - val_mean_absolute_error: 586.1266\n",
      "Epoch 15/25\n",
      "940/940 [==============================] - 2s - loss: 83393.3127 - mean_absolute_error: 245.3897 - val_loss: 315480.0812 - val_mean_absolute_error: 561.6580\n",
      "Epoch 16/25\n",
      "940/940 [==============================] - 2s - loss: 79448.6856 - mean_absolute_error: 241.3560 - val_loss: 292848.7000 - val_mean_absolute_error: 541.1379\n",
      "Epoch 17/25\n",
      "940/940 [==============================] - 2s - loss: 76957.9263 - mean_absolute_error: 238.5458 - val_loss: 275025.2313 - val_mean_absolute_error: 524.4128\n",
      "Epoch 18/25\n",
      "940/940 [==============================] - 2s - loss: 75483.1949 - mean_absolute_error: 236.8628 - val_loss: 261214.7969 - val_mean_absolute_error: 511.0774\n",
      "Epoch 19/25\n",
      "940/940 [==============================] - 2s - loss: 74648.7581 - mean_absolute_error: 236.0541 - val_loss: 251664.2188 - val_mean_absolute_error: 501.6484\n",
      "Epoch 20/25\n",
      "940/940 [==============================] - 2s - loss: 74187.1085 - mean_absolute_error: 235.5424 - val_loss: 244400.6656 - val_mean_absolute_error: 494.3569\n",
      "Epoch 21/25\n",
      "940/940 [==============================] - 2s - loss: 73926.3921 - mean_absolute_error: 235.3086 - val_loss: 239013.2062 - val_mean_absolute_error: 488.8786\n",
      "Epoch 22/25\n",
      "940/940 [==============================] - 2s - loss: 73800.3027 - mean_absolute_error: 235.2070 - val_loss: 235248.4719 - val_mean_absolute_error: 485.0137\n",
      "Epoch 23/25\n",
      "940/940 [==============================] - 2s - loss: 73727.4770 - mean_absolute_error: 235.0897 - val_loss: 232439.6938 - val_mean_absolute_error: 482.1100\n",
      "Epoch 24/25\n",
      "940/940 [==============================] - 2s - loss: 73695.6031 - mean_absolute_error: 235.0453 - val_loss: 230740.8469 - val_mean_absolute_error: 480.3453\n",
      "Epoch 25/25\n",
      "940/940 [==============================] - 2s - loss: 73675.5719 - mean_absolute_error: 235.0641 - val_loss: 228869.1656 - val_mean_absolute_error: 478.3933\n",
      "\n",
      "\n",
      "actual\tpredicted\n",
      "[ 990 -990]\t[ 516.96002197 -515.2532959 ]\n",
      "[ 991 -991]\t[ 516.96002197 -515.2532959 ]\n",
      "[ 992 -992]\t[ 516.96002197 -515.2532959 ]\n",
      "[ 993 -993]\t[ 516.96002197 -515.2532959 ]\n",
      "[ 994 -994]\t[ 516.96002197 -515.2532959 ]\n",
      "[ 995 -995]\t[ 516.96002197 -515.2532959 ]\n",
      "[ 996 -996]\t[ 516.96002197 -515.2532959 ]\n",
      "[ 997 -997]\t[ 516.96002197 -515.2532959 ]\n",
      "[ 998 -998]\t[ 516.96002197 -515.2532959 ]\n",
      "[ 999 -999]\t[ 516.96002197 -515.2532959 ]\n",
      "next\t[ 516.96002197 -515.2532959 ]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example of using Keras to implement a 1D convolutional neural network (CNN) for timeseries prediction.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "__date__ = '2016-07-22'\n",
    "\n",
    "\n",
    "def make_timeseries_regressor(window_size, filter_length, nb_input_series=1, nb_outputs=1, nb_filter=4):\n",
    "    \"\"\":Return: a Keras Model for predicting the next value in a timeseries given a fixed-size lookback window of previous values.\n",
    "\n",
    "    The model can handle multiple input timeseries (`nb_input_series`) and multiple prediction targets (`nb_outputs`).\n",
    "\n",
    "    :param int window_size: The number of previous timeseries values to use as input features.  Also called lag or lookback.\n",
    "    :param int nb_input_series: The number of input timeseries; 1 for a single timeseries.\n",
    "      The `X` input to ``fit()`` should be an array of shape ``(n_instances, window_size, nb_input_series)``; each instance is\n",
    "      a 2D array of shape ``(window_size, nb_input_series)``.  For example, for `window_size` = 3 and `nb_input_series` = 1 (a\n",
    "      single timeseries), one instance could be ``[[0], [1], [2]]``. See ``make_timeseries_instances()``.\n",
    "    :param int nb_outputs: The output dimension, often equal to the number of inputs.\n",
    "      For each input instance (array with shape ``(window_size, nb_input_series)``), the output is a vector of size `nb_outputs`,\n",
    "      usually the value(s) predicted to come after the last value in that input instance, i.e., the next value\n",
    "      in the sequence. The `y` input to ``fit()`` should be an array of shape ``(n_instances, nb_outputs)``.\n",
    "    :param int filter_length: the size (along the `window_size` dimension) of the sliding window that gets convolved with\n",
    "      each position along each instance. The difference between 1D and 2D convolution is that a 1D filter's \"height\" is fixed\n",
    "      to the number of input timeseries (its \"width\" being `filter_length`), and it can only slide along the window\n",
    "      dimension.  This is useful as generally the input timeseries have no spatial/ordinal relationship, so it's not\n",
    "      meaningful to look for patterns that are invariant with respect to subsets of the timeseries.\n",
    "    :param int nb_filter: The number of different filters to learn (roughly, input patterns to recognize).\n",
    "    \"\"\"\n",
    "    model = Sequential((\n",
    "        # The first conv layer learns `nb_filter` filters (aka kernels), each of size ``(filter_length, nb_input_series)``.\n",
    "        # Its output will have shape (None, window_size - filter_length + 1, nb_filter), i.e., for each position in\n",
    "        # the input timeseries, the activation of each filter at that position.\n",
    "        Convolution1D(nb_filter=nb_filter, filter_length=filter_length, activation='relu', input_shape=(window_size, nb_input_series)),\n",
    "        MaxPooling1D(),     # Downsample the output of convolution by 2X.\n",
    "        Convolution1D(nb_filter=nb_filter, filter_length=filter_length, activation='relu'),\n",
    "        MaxPooling1D(),\n",
    "        Flatten(),\n",
    "        Dense(nb_outputs, activation='linear'),     # For binary classification, change the activation to 'sigmoid'\n",
    "    ))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "    # To perform (binary) classification instead:\n",
    "    # model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_timeseries_instances(timeseries, window_size):\n",
    "    \"\"\"Make input features and prediction targets from a `timeseries` for use in machine learning.\n",
    "\n",
    "    :return: A tuple of `(X, y, q)`.  `X` are the inputs to a predictor, a 3D ndarray with shape\n",
    "      ``(timeseries.shape[0] - window_size, window_size, timeseries.shape[1] or 1)``.  For each row of `X`, the\n",
    "      corresponding row of `y` is the next value in the timeseries.  The `q` or query is the last instance, what you would use\n",
    "      to predict a hypothetical next (unprovided) value in the `timeseries`.\n",
    "    :param ndarray timeseries: Either a simple vector, or a matrix of shape ``(timestep, series_num)``, i.e., time is axis 0 (the\n",
    "      row) and the series is axis 1 (the column).\n",
    "    :param int window_size: The number of samples to use as input prediction features (also called the lag or lookback).\n",
    "    \"\"\"\n",
    "    timeseries = np.asarray(timeseries)\n",
    "    assert 0 < window_size < timeseries.shape[0]\n",
    "    X = np.atleast_3d(np.array([timeseries[start:start + window_size] for start in range(0, timeseries.shape[0] - window_size)]))\n",
    "    y = timeseries[window_size:]\n",
    "    q = np.atleast_3d([timeseries[-window_size:]])\n",
    "    return X, y, q\n",
    "\n",
    "\n",
    "def evaluate_timeseries(timeseries, window_size):\n",
    "    \"\"\"Create a 1D CNN regressor to predict the next value in a `timeseries` using the preceding `window_size` elements\n",
    "    as input features and evaluate its performance.\n",
    "\n",
    "    :param ndarray timeseries: Timeseries data with time increasing down the rows (the leading dimension/axis).\n",
    "    :param int window_size: The number of previous timeseries values to use to predict the next.\n",
    "    \"\"\"\n",
    "    filter_length = 5\n",
    "    nb_filter = 4\n",
    "    timeseries = np.atleast_2d(timeseries)\n",
    "    if timeseries.shape[0] == 1:\n",
    "        timeseries = timeseries.T       # Convert 1D vectors to 2D column vectors\n",
    "\n",
    "    nb_samples, nb_series = timeseries.shape\n",
    "    print('\\n\\nTimeseries ({} samples by {} series):\\n'.format(nb_samples, nb_series), timeseries)\n",
    "    model = make_timeseries_regressor(window_size=window_size, filter_length=filter_length, nb_input_series=nb_series, nb_outputs=nb_series, nb_filter=nb_filter)\n",
    "    print('\\n\\nModel with input size {}, output size {}, {} conv filters of length {}'.format(model.input_shape, model.output_shape, nb_filter, filter_length))\n",
    "    model.summary()\n",
    "\n",
    "    X, y, q = make_timeseries_instances(timeseries, window_size)\n",
    "    print('\\n\\nInput features:', X, '\\n\\nOutput labels:', y, '\\n\\nQuery vector:', q, sep='\\n')\n",
    "    test_size = int(0.01 * nb_samples)           # In real life you'd want to use 0.2 - 0.5\n",
    "    X_train, X_test, y_train, y_test = X[:-test_size], X[-test_size:], y[:-test_size], y[-test_size:]\n",
    "    model.fit(X_train, y_train, nb_epoch=25, batch_size=2, validation_data=(X_test, y_test))\n",
    "\n",
    "    pred = model.predict(X_test)\n",
    "    print('\\n\\nactual', 'predicted', sep='\\t')\n",
    "    for actual, predicted in zip(y_test, pred.squeeze()):\n",
    "        print(actual.squeeze(), predicted, sep='\\t')\n",
    "    print('next', model.predict(q).squeeze(), sep='\\t')\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Prepare input data, build model, evaluate.\"\"\"\n",
    "    np.set_printoptions(threshold=25)\n",
    "    ts_length = 1000\n",
    "    window_size = 50\n",
    "\n",
    "    print('\\nSimple single timeseries vector prediction')\n",
    "    timeseries = np.arange(ts_length)                   # The timeseries f(t) = t\n",
    "    evaluate_timeseries(timeseries, window_size)\n",
    "\n",
    "    print('\\nMultiple-input, multiple-output prediction')\n",
    "    timeseries = np.array([np.arange(ts_length), -np.arange(ts_length)]).T      # The timeseries f(t) = [t, -t]\n",
    "    evaluate_timeseries(timeseries, window_size)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
