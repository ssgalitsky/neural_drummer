{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pywt\n",
    "import inspect\n",
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Embedding, LSTM, Activation, Input, Dropout, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "# from keras.layers import LSTM\n",
    "import scipy.io.wavfile as wavfile\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input_rate, input_signal = wavfile.read('data/1clean_Selection.wav')\n",
    "# output_rate, output_signal = wavfile.read('data/1Selection.wav')\n",
    "# input_rate, input_signal = wavfile.read('data/beatzzz/Clean Beat 01.wav')\n",
    "# output_rate, output_signal = wavfile.read('data/beatzzz/Processed Beat 03.wav')\n",
    "input_rate, input_signal = wavfile.read('data/beat2/Clean Beat 02.wav')\n",
    "output_rate, output_signal = wavfile.read('data/beat2/Processed Beat 02_02.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing out pywt functions and reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input rate: 44100\n",
      "for 5 ms samples, input sample length is: 220\n",
      "Max wave level decomposition: 3\n",
      "input signal shape: (2419200, 2)\n",
      "coefficients shapes: 4, [302416, 302416, 604814, 1209609]\n",
      "coefficients type: <type 'numpy.ndarray'>\n",
      "reconstruction shape: (2419200, 2)\n",
      "['bior1.1', 'bior1.3', 'bior1.5', 'bior2.2', 'bior2.4', 'bior2.6', 'bior2.8', 'bior3.1', 'bior3.3', 'bior3.5', 'bior3.7', 'bior3.9', 'bior4.4', 'bior5.5', 'bior6.8', 'cgau1', 'cgau2', 'cgau3', 'cgau4', 'cgau5', 'cgau6', 'cgau7', 'cgau8', 'cmor', 'coif1', 'coif2', 'coif3', 'coif4', 'coif5', 'coif6', 'coif7', 'coif8', 'coif9', 'coif10', 'coif11', 'coif12', 'coif13', 'coif14', 'coif15', 'coif16', 'coif17', 'db1', 'db2', 'db3', 'db4', 'db5', 'db6', 'db7', 'db8', 'db9', 'db10', 'db11', 'db12', 'db13', 'db14', 'db15', 'db16', 'db17', 'db18', 'db19', 'db20', 'db21', 'db22', 'db23', 'db24', 'db25', 'db26', 'db27', 'db28', 'db29', 'db30', 'db31', 'db32', 'db33', 'db34', 'db35', 'db36', 'db37', 'db38', 'dmey', 'fbsp', 'gaus1', 'gaus2', 'gaus3', 'gaus4', 'gaus5', 'gaus6', 'gaus7', 'gaus8', 'haar', 'mexh', 'morl', 'rbio1.1', 'rbio1.3', 'rbio1.5', 'rbio2.2', 'rbio2.4', 'rbio2.6', 'rbio2.8', 'rbio3.1', 'rbio3.3', 'rbio3.5', 'rbio3.7', 'rbio3.9', 'rbio4.4', 'rbio5.5', 'rbio6.8', 'shan', 'sym2', 'sym3', 'sym4', 'sym5', 'sym6', 'sym7', 'sym8', 'sym9', 'sym10', 'sym11', 'sym12', 'sym13', 'sym14', 'sym15', 'sym16', 'sym17', 'sym18', 'sym19', 'sym20']\n"
     ]
    }
   ],
   "source": [
    "# some settings:\n",
    "wavetype = 'db10'\n",
    "# wavelevel = 15\n",
    "\n",
    "print(\"input rate: \" + str(input_rate))\n",
    "sample_length = input_rate//200\n",
    "print(\"for 5 ms samples, input sample length is: \" + str(sample_length))\n",
    "\n",
    "w = pywt.Wavelet(wavetype)\n",
    "wavelevel = pywt.dwt_max_level(data_len=sample_length, filter_len=w.dec_len)\n",
    "\n",
    "# set a little lower:\n",
    "# wavelevel = 1\n",
    "print(\"Max wave level decomposition: \" + str(wavelevel))\n",
    "\n",
    "# these are floats, original is int16\n",
    "input_coeffs1 = pywt.wavedec(input_signal[:,0].T, wavetype, level=wavelevel)\n",
    "input_coeffs2 = pywt.wavedec(input_signal[:,1].T, wavetype, level=wavelevel)\n",
    "# output_coeffs1 = pywt.wavedec(output_signal[:,0].T, wavetype, level=wavelevel)\n",
    "# output_coeffs2 = pywt.wavedec(output_signal[:,1].T, wavetype, level=wavelevel)\n",
    "print(\"input signal shape: \" + str(input_signal.shape))\n",
    "\n",
    "# reconstruction for left and right channel\n",
    "recons1 = np.array([pywt.waverec(input_coeffs1, wavetype)]).astype('int16')\n",
    "recons2 = np.array([pywt.waverec(input_coeffs2, wavetype)]).astype('int16')\n",
    "\n",
    "# print(recons1.shape)\n",
    "print(\"coefficients shapes: \" + str(len(input_coeffs1)) + \", \" + str([len(j) for j in input_coeffs1]))\n",
    "print(\"coefficients type: \" + str(type(input_coeffs1[0])))\n",
    "\n",
    "write_array = np.concatenate((recons1,recons2),axis=0).T\n",
    "print('reconstruction shape: ' + str(write_array.shape))\n",
    "\n",
    "# output wav for auditory test\n",
    "wavfile.write('output/recons.wav', input_rate, write_array)\n",
    "\n",
    "# get available wavelets\n",
    "print(pywt.wavelist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 -1 -1 -2 -2 -3 -2 -2 -1 -1]\n",
      "[ 0  0 -1 -2 -2 -3 -2 -2 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "print(input_signal[:10,0].T)\n",
    "print(recons1[0,:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare data for keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# functions for pre-processing and reconstruction of training vectors\n",
    "# first function is over a batch - need smaller size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DEPRECATED\n",
    "def wavelet_to_vector_all(input_raw, output_raw, chunk_size, wavelet_level, wavelet_type):\n",
    "    current_set = 'input'\n",
    "    \n",
    "    w = pywt.Wavelet(wavelet_type)\n",
    "    max_level = pywt.dwt_max_level(data_len=chunk_size, filter_len=w.dec_len)\n",
    "    if wavelet_level > max_level:\n",
    "        print('wavelet level too high. set to max level: ' + str(max_level))\n",
    "        wavelet_level = max_level\n",
    "    \n",
    "    # short hacky loop\n",
    "    while True:\n",
    "        # select the correct set\n",
    "        if current_set == 'input':\n",
    "            data = input_raw\n",
    "            amount_of_chunks = int(math.floor(data.shape[0]/chunk_size))\n",
    "            input_list = []\n",
    "            print('Amount of samples: ' + str(amount_of_chunks))\n",
    "        else:\n",
    "            data = output_raw\n",
    "            amount_of_chunks = int(math.floor(data.shape[0]/chunk_size))\n",
    "            output_list = []\n",
    "        \n",
    "        index_range = (np.arange(amount_of_chunks) * chunk_size)\n",
    "        indp = chunk_size - 1\n",
    "        # for all chunks do this:\n",
    "        for ind in index_range:\n",
    "#             print(ind)\n",
    "            sample1 = data[ind:ind+indp,0].T\n",
    "            sample2 = data[ind:ind+indp,1].T\n",
    "            coeffs1 = pywt.wavedec(sample1, wavelet_type, level=wavelet_level)\n",
    "            coeffs2 = pywt.wavedec(sample2, wavelet_type, level=wavelet_level)\n",
    "            unfolded1 = np.array([item for sublist in coeffs1 for item in sublist])\n",
    "            unfolded2 = np.array([item for sublist in coeffs2 for item in sublist])\n",
    "            # POSSIBLE MISTAKE: puts l/r in one big sequence\n",
    "            # run on mono first\n",
    "            vector = np.concatenate((unfolded1,unfolded2),axis=0)\n",
    "            \n",
    "            if current_set == 'input':\n",
    "                input_list.append(vector)\n",
    "            else:\n",
    "                output_list.append(vector)\n",
    "#             unf_arr = np.array(unfolded1)\n",
    "#             print(unf_arr.shape)\n",
    "#             print(len(unfolded))\n",
    "            \n",
    "            # for all coeff levels:\n",
    "#             for i in range(len(coeffs1)):\n",
    "#                 print(i)\n",
    "            \n",
    "        \n",
    "        \n",
    "        if current_set == 'output':\n",
    "            break\n",
    "        current_set = 'output'\n",
    "\n",
    "    # convert lists to arrays\n",
    "    input_arr = np.array(input_list)\n",
    "    output_arr = np.array(output_list)\n",
    "    \n",
    "    # print stats for converting back to audio\n",
    "    wavelet_lengths = [len(j) for j in coeffs1]\n",
    "    ind = 0\n",
    "    index_list = [0]\n",
    "    for w_l in wavelet_lengths:\n",
    "        ind += w_l\n",
    "        index_list.append(ind)\n",
    "    print(\"length of different wavelet bands: \" + str(wavelet_lengths))\n",
    "    print(\"indexes: \" + str(index_list))\n",
    "    print(\"more sizes? \" + str([len(sublist) for sublist in coeffs1]))\n",
    "    # return level sizes for reconstruction\n",
    "    level_sizes = []\n",
    "    for cf in coeffs1:\n",
    "        level_sizes.append(cf.shape[0])\n",
    "    return [input_arr, output_arr, level_sizes]\n",
    "# input_coeffs1[16].shape\n",
    "\n",
    "# rows=samples, cols=dim\n",
    "# [input_matrix, output_matrix, level_sizes] = wavelet_to_vector_all(input_signal, output_signal, sample_length, wavelevel, 'db4')\n",
    "# print(input_matrix.shape)\n",
    "# print(level_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices where vector should be sliced: [0, 44, 88, 157, 276]\n"
     ]
    }
   ],
   "source": [
    "# some info\n",
    "wav_lengths = [44, 44, 69, 119]\n",
    "wav_indices = [0]\n",
    "for length in wav_lengths:\n",
    "    wav_indices.append(wav_indices[-1]+length)\n",
    "print(\"indices where vector should be sliced: \" + str(wav_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for a single audio slice (mono)\n",
    "def audio_to_vector(input_mono, wavelet_level, wavelet_type):\n",
    "    coeffs = pywt.wavedec(input_mono, wavelet_type, level=wavelet_level)\n",
    "#     print([len(co) for co in coeffs])\n",
    "#     vector = np.array([item for sublist in coeffs for item in sublist])\n",
    "#     vector = np.array([])\n",
    "    vector = np.concatenate(coeffs)\n",
    "#     for band in coeffs:\n",
    "#         vector.append\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for a single output vector (mono)\n",
    "def vector_to_list(input_vector, indexes=wav_indices):\n",
    "    # unflatten the vector\n",
    "#     for i in range(len(indexes)-1):\n",
    "#         wavelet_list.append(input_vector[indexes[i]:indexes[i+1]])\n",
    "    # use np.split\n",
    "    wavelet_list = np.split(input_vector, indexes[1:-1])\n",
    "    return wavelet_list\n",
    "#     wavelet_list = [input_vector[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector length: 276\n",
      "113236.704732\n",
      "-112970.705528\n",
      "85259.6801722\n",
      "-84449.9845834\n",
      "113236.704732\n",
      "(21992, 276)\n"
     ]
    }
   ],
   "source": [
    "# create new (mono) data set\n",
    "# for both channels, we just handle mono samples:\n",
    "mono_input = []\n",
    "mono_output = []\n",
    "for side in (0,1):\n",
    "    total_raw_in = input_signal[:,side]\n",
    "    total_raw_out = output_signal[:,side]\n",
    "    number_of_chunks = total_raw_in.shape[0]//sample_length\n",
    "#     print(number_of_chunks)\n",
    "    for ind in range(number_of_chunks):\n",
    "        start_ind = ind*sample_length\n",
    "        end_ind = ind*sample_length + sample_length\n",
    "        curr_in_sample = total_raw_in[start_ind:end_ind]\n",
    "        curr_out_sample = total_raw_out[start_ind:end_ind]\n",
    "        in_vec = audio_to_vector(curr_in_sample, wavelevel, wavetype)\n",
    "        out_vec = audio_to_vector(curr_out_sample, wavelevel, wavetype)\n",
    "        mono_input.append(in_vec)\n",
    "        mono_output.append(out_vec)\n",
    "#     print(curr_in_sample.shape)\n",
    "vec_length = in_vec.shape[0]\n",
    "print(\"vector length: \" +str(vec_length))\n",
    "mono_input = np.array(mono_input)\n",
    "mono_output = np.array(mono_output)\n",
    "\n",
    "print(np.max(mono_input))\n",
    "print(np.min(mono_input))\n",
    "print(np.max(mono_output))\n",
    "print(np.min(mono_output))\n",
    "# max seems to be about 100000, so scale it to that range:\n",
    "# not necessary for linear activation i think...\n",
    "# mono_input = mono_input/100000\n",
    "# mono_output = mono_output/100000\n",
    "print(np.max(mono_input))\n",
    "\n",
    "print(mono_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4838240)\n",
      "2\n",
      "reconstruction shape: (2419120, 2)\n"
     ]
    }
   ],
   "source": [
    "# now put some of it back into audio form to test the representation's audio quality\n",
    "reconstruction_array = []\n",
    "for i in range(mono_output.shape[0]):\n",
    "    coeffs = vector_to_list(mono_output[i,:])\n",
    "    rec_arr = np.array([pywt.waverec(coeffs, wavetype)]).astype('int16')\n",
    "    reconstruction_array.append(rec_arr)\n",
    "\n",
    "reconstruction_array = np.concatenate(reconstruction_array,axis=1)\n",
    "print(reconstruction_array.shape)\n",
    "# write_array = np.reshape(reconstruction_array, (-1,2))\n",
    "rec_split = np.split(reconstruction_array.T, 2)\n",
    "print(len(rec_split))\n",
    "\n",
    "write_array = np.concatenate((rec_split[0], rec_split[1]),axis=1)\n",
    "print('reconstruction shape: ' + str(write_array.shape))\n",
    "\n",
    "# output wav for auditory test\n",
    "wavfile.write('output/recons_new.wav', input_rate, write_array)\n",
    "# scientific analysis: sounds fine to me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build the first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Epoch 1/170\n",
      "21992/21992 [==============================] - 1s - loss: 43420409.4769     \n",
      "Epoch 2/170\n",
      "21992/21992 [==============================] - 0s - loss: 40530050.6002     \n",
      "Epoch 3/170\n",
      "21992/21992 [==============================] - 0s - loss: 40115747.9302     \n",
      "Epoch 4/170\n",
      "21992/21992 [==============================] - 0s - loss: 39816326.2728     \n",
      "Epoch 5/170\n",
      "21992/21992 [==============================] - 0s - loss: 39568942.7035     \n",
      "Epoch 6/170\n",
      "21992/21992 [==============================] - 0s - loss: 39406290.9916     \n",
      "Epoch 7/170\n",
      "21992/21992 [==============================] - 0s - loss: 39281359.7672     \n",
      "Epoch 8/170\n",
      "21992/21992 [==============================] - 0s - loss: 39131589.8436     \n",
      "Epoch 9/170\n",
      "21992/21992 [==============================] - 0s - loss: 39045080.9720     \n",
      "Epoch 10/170\n",
      "21992/21992 [==============================] - 0s - loss: 38915423.1211     \n",
      "Epoch 11/170\n",
      "21992/21992 [==============================] - 0s - loss: 38848405.6835     \n",
      "Epoch 12/170\n",
      "21992/21992 [==============================] - 0s - loss: 38756933.4274     \n",
      "Epoch 13/170\n",
      "21992/21992 [==============================] - 0s - loss: 38695419.4638     \n",
      "Epoch 14/170\n",
      "21992/21992 [==============================] - 0s - loss: 38568494.5464     \n",
      "Epoch 15/170\n",
      "21992/21992 [==============================] - 0s - loss: 38525224.8061     \n",
      "Epoch 16/170\n",
      "21992/21992 [==============================] - 0s - loss: 38414725.1946     \n",
      "Epoch 17/170\n",
      "21992/21992 [==============================] - 0s - loss: 38317915.7555     \n",
      "Epoch 18/170\n",
      "21992/21992 [==============================] - 0s - loss: 38242809.0491     \n",
      "Epoch 19/170\n",
      "21992/21992 [==============================] - 0s - loss: 38107822.6526     \n",
      "Epoch 20/170\n",
      "21992/21992 [==============================] - 0s - loss: 38099602.7690     \n",
      "Epoch 21/170\n",
      "21992/21992 [==============================] - 0s - loss: 38009692.0451     \n",
      "Epoch 22/170\n",
      "21992/21992 [==============================] - 0s - loss: 37885786.2656     \n",
      "Epoch 23/170\n",
      "21992/21992 [==============================] - 0s - loss: 37806018.2423     \n",
      "Epoch 24/170\n",
      "21992/21992 [==============================] - 0s - loss: 37747519.3176     \n",
      "Epoch 25/170\n",
      "21992/21992 [==============================] - 0s - loss: 37622382.9814     \n",
      "Epoch 26/170\n",
      "21992/21992 [==============================] - 0s - loss: 37468600.0480     \n",
      "Epoch 27/170\n",
      "21992/21992 [==============================] - 0s - loss: 37379652.6810     \n",
      "Epoch 28/170\n",
      "21992/21992 [==============================] - 0s - loss: 37357542.6657     \n",
      "Epoch 29/170\n",
      "21992/21992 [==============================] - 0s - loss: 37188953.0884     \n",
      "Epoch 30/170\n",
      "21992/21992 [==============================] - 0s - loss: 37035669.7905     \n",
      "Epoch 31/170\n",
      "21992/21992 [==============================] - 0s - loss: 37068333.9105     \n",
      "Epoch 32/170\n",
      "21992/21992 [==============================] - 0s - loss: 36982826.5755     \n",
      "Epoch 33/170\n",
      "21992/21992 [==============================] - 0s - loss: 36856621.9222     \n",
      "Epoch 34/170\n",
      "21992/21992 [==============================] - 0s - loss: 36777839.7672     \n",
      "Epoch 35/170\n",
      "21992/21992 [==============================] - 0s - loss: 36647674.2452     \n",
      "Epoch 36/170\n",
      "21992/21992 [==============================] - 0s - loss: 36548567.1444     \n",
      "Epoch 37/170\n",
      "21992/21992 [==============================] - 0s - loss: 36448429.2645     \n",
      "Epoch 38/170\n",
      "21992/21992 [==============================] - 0s - loss: 36310213.1873     \n",
      "Epoch 39/170\n",
      "21992/21992 [==============================] - 0s - loss: 36213595.1415     \n",
      "Epoch 40/170\n",
      "21992/21992 [==============================] - 0s - loss: 36067444.5078     \n",
      "Epoch 41/170\n",
      "21992/21992 [==============================] - 0s - loss: 35944382.7239     \n",
      "Epoch 42/170\n",
      "21992/21992 [==============================] - 0s - loss: 35861891.7323     \n",
      "Epoch 43/170\n",
      "21992/21992 [==============================] - 0s - loss: 35776246.6060     \n",
      "Epoch 44/170\n",
      "21992/21992 [==============================] - 0s - loss: 35725661.3605     \n",
      "Epoch 45/170\n",
      "21992/21992 [==============================] - 0s - loss: 35540708.2372     \n",
      "Epoch 46/170\n",
      "21992/21992 [==============================] - 0s - loss: 35566697.4274     \n",
      "Epoch 47/170\n",
      "21992/21992 [==============================] - 0s - loss: 35461315.4776     \n",
      "Epoch 48/170\n",
      "21992/21992 [==============================] - 0s - loss: 35308071.7606     \n",
      "Epoch 49/170\n",
      "21992/21992 [==============================] - 0s - loss: 35163927.5169     \n",
      "Epoch 50/170\n",
      "21992/21992 [==============================] - 0s - loss: 35079038.2961     \n",
      "Epoch 51/170\n",
      "21992/21992 [==============================] - 0s - loss: 34986143.9243     \n",
      "Epoch 52/170\n",
      "21992/21992 [==============================] - 0s - loss: 34981312.8236     \n",
      "Epoch 53/170\n",
      "21992/21992 [==============================] - 0s - loss: 34846336.5282     \n",
      "Epoch 54/170\n",
      "21992/21992 [==============================] - 0s - loss: 34647832.3492     \n",
      "Epoch 55/170\n",
      "21992/21992 [==============================] - 0s - loss: 34579169.1015     \n",
      "Epoch 56/170\n",
      "21992/21992 [==============================] - 0s - loss: 34468068.7406     \n",
      "Epoch 57/170\n",
      "21992/21992 [==============================] - 0s - loss: 34334535.4194     \n",
      "Epoch 58/170\n",
      "21992/21992 [==============================] - 0s - loss: 34281408.3587     \n",
      "Epoch 59/170\n",
      "21992/21992 [==============================] - 0s - loss: 34084728.6621     \n",
      "Epoch 60/170\n",
      "21992/21992 [==============================] - 0s - loss: 34090612.6868     \n",
      "Epoch 61/170\n",
      "21992/21992 [==============================] - 0s - loss: 33833817.0258     \n",
      "Epoch 62/170\n",
      "21992/21992 [==============================] - 0s - loss: 33881137.8683     \n",
      "Epoch 63/170\n",
      "21992/21992 [==============================] - 0s - loss: 33676811.5606     \n",
      "Epoch 64/170\n",
      "21992/21992 [==============================] - 0s - loss: 33635099.0302     \n",
      "Epoch 65/170\n",
      "21992/21992 [==============================] - 0s - loss: 33497664.1135     \n",
      "Epoch 66/170\n",
      "21992/21992 [==============================] - 0s - loss: 33411061.6544     \n",
      "Epoch 67/170\n",
      "21992/21992 [==============================] - 0s - loss: 33369926.9101     \n",
      "Epoch 68/170\n",
      "21992/21992 [==============================] - 0s - loss: 33151376.8010     \n",
      "Epoch 69/170\n",
      "21992/21992 [==============================] - 0s - loss: 33082825.7876     \n",
      "Epoch 70/170\n",
      "21992/21992 [==============================] - 0s - loss: 33066166.6039     \n",
      "Epoch 71/170\n",
      "21992/21992 [==============================] - 0s - loss: 32897922.6344     \n",
      "Epoch 72/170\n",
      "21992/21992 [==============================] - 0s - loss: 32833425.9571     \n",
      "Epoch 73/170\n",
      "21992/21992 [==============================] - 0s - loss: 32630663.5220     \n",
      "Epoch 74/170\n",
      "21992/21992 [==============================] - 0s - loss: 32506997.4798     \n",
      "Epoch 75/170\n",
      "21992/21992 [==============================] - 0s - loss: 32585992.0575     \n",
      "Epoch 76/170\n",
      "21992/21992 [==============================] - 0s - loss: 32458066.1448     \n",
      "Epoch 77/170\n",
      "21992/21992 [==============================] - 0s - loss: 32192522.1761     \n",
      "Epoch 78/170\n",
      "21992/21992 [==============================] - 0s - loss: 32244113.2848     \n",
      "Epoch 79/170\n",
      "21992/21992 [==============================] - 0s - loss: 32020534.6148     \n",
      "Epoch 80/170\n",
      "21992/21992 [==============================] - 0s - loss: 32043560.6708     \n",
      "Epoch 81/170\n",
      "21992/21992 [==============================] - 0s - loss: 31903351.4456     \n",
      "Epoch 82/170\n",
      "21992/21992 [==============================] - 0s - loss: 31778078.6031     \n",
      "Epoch 83/170\n",
      "21992/21992 [==============================] - 0s - loss: 31587895.2754     \n",
      "Epoch 84/170\n",
      "21992/21992 [==============================] - 0s - loss: 31606078.6475     \n",
      "Epoch 85/170\n",
      "21992/21992 [==============================] - 0s - loss: 31482387.7730     \n",
      "Epoch 86/170\n",
      "21992/21992 [==============================] - 0s - loss: 31324926.2277     \n",
      "Epoch 87/170\n",
      "21992/21992 [==============================] - 0s - loss: 31245331.2026     \n",
      "Epoch 88/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21992/21992 [==============================] - 0s - loss: 31244487.1932     \n",
      "Epoch 89/170\n",
      "21992/21992 [==============================] - 0s - loss: 31120256.8119     \n",
      "Epoch 90/170\n",
      "21992/21992 [==============================] - 0s - loss: 30946177.6260     \n",
      "Epoch 91/170\n",
      "21992/21992 [==============================] - 0s - loss: 31036556.9203     \n",
      "Epoch 92/170\n",
      "21992/21992 [==============================] - 0s - loss: 30813659.3787     \n",
      "Epoch 93/170\n",
      "21992/21992 [==============================] - 0s - loss: 30866139.4063     \n",
      "Epoch 94/170\n",
      "21992/21992 [==============================] - 0s - loss: 30861965.5569     \n",
      "Epoch 95/170\n",
      "21992/21992 [==============================] - 0s - loss: 30488111.3670     \n",
      "Epoch 96/170\n",
      "21992/21992 [==============================] - 0s - loss: 30516005.3750     \n",
      "Epoch 97/170\n",
      "21992/21992 [==============================] - 0s - loss: 30471182.5136     \n",
      "Epoch 98/170\n",
      "21992/21992 [==============================] - 0s - loss: 30393394.4198     \n",
      "Epoch 99/170\n",
      "21992/21992 [==============================] - 0s - loss: 30278936.4940     \n",
      "Epoch 100/170\n",
      "21992/21992 [==============================] - 0s - loss: 30102816.9240     \n",
      "Epoch 101/170\n",
      "21992/21992 [==============================] - 0s - loss: 30170883.4682     \n",
      "Epoch 102/170\n",
      "21992/21992 [==============================] - 0s - loss: 29975395.3743     \n",
      "Epoch 103/170\n",
      "21992/21992 [==============================] - 0s - loss: 29820844.2495     \n",
      "Epoch 104/170\n",
      "21992/21992 [==============================] - 0s - loss: 29798108.8265     \n",
      "Epoch 105/170\n",
      "21992/21992 [==============================] - 0s - loss: 29683104.7887     \n",
      "Epoch 106/170\n",
      "21992/21992 [==============================] - 0s - loss: 29462935.1051     \n",
      "Epoch 107/170\n",
      "21992/21992 [==============================] - 0s - loss: 29485316.6933     \n",
      "Epoch 108/170\n",
      "21992/21992 [==============================] - 0s - loss: 29580822.5806     \n",
      "Epoch 109/170\n",
      "21992/21992 [==============================] - 0s - loss: 29217765.6311     \n",
      "Epoch 110/170\n",
      "21992/21992 [==============================] - 0s - loss: 29101645.0622     \n",
      "Epoch 111/170\n",
      "21992/21992 [==============================] - 0s - loss: 29214819.4252     \n",
      "Epoch 112/170\n",
      "21992/21992 [==============================] - 0s - loss: 28959401.9862     \n",
      "Epoch 113/170\n",
      "21992/21992 [==============================] - 0s - loss: 29052458.0822     \n",
      "Epoch 114/170\n",
      "21992/21992 [==============================] - 0s - loss: 28817622.4627     \n",
      "Epoch 115/170\n",
      "21992/21992 [==============================] - 0s - loss: 28786415.2303     \n",
      "Epoch 116/170\n",
      "21992/21992 [==============================] - 0s - loss: 28712758.3398     \n",
      "Epoch 117/170\n",
      "21992/21992 [==============================] - 0s - loss: 28604087.0455     \n",
      "Epoch 118/170\n",
      "21992/21992 [==============================] - 0s - loss: 28630991.0004     \n",
      "Epoch 119/170\n",
      "21992/21992 [==============================] - 0s - loss: 28423141.5919     \n",
      "Epoch 120/170\n",
      "21992/21992 [==============================] - 0s - loss: 28328275.1611     \n",
      "Epoch 121/170\n",
      "21992/21992 [==============================] - 0s - loss: 28313130.3754     \n",
      "Epoch 122/170\n",
      "21992/21992 [==============================] - 0s - loss: 28399614.8163     \n",
      "Epoch 123/170\n",
      "21992/21992 [==============================] - 0s - loss: 28196489.6246     \n",
      "Epoch 124/170\n",
      "21992/21992 [==============================] - 0s - loss: 28073696.6861     \n",
      "Epoch 125/170\n",
      "21992/21992 [==============================] - 0s - loss: 27928429.8785     \n",
      "Epoch 126/170\n",
      "21992/21992 [==============================] - 0s - loss: 27993359.8188     \n",
      "Epoch 127/170\n",
      "21992/21992 [==============================] - 0s - loss: 27961516.4554     \n",
      "Epoch 128/170\n",
      "21992/21992 [==============================] - 0s - loss: 27744600.5471     \n",
      "Epoch 129/170\n",
      "21992/21992 [==============================] - 0s - loss: 27766300.9058     \n",
      "Epoch 130/170\n",
      "21992/21992 [==============================] - 0s - loss: 27604618.3514     \n",
      "Epoch 131/170\n",
      "21992/21992 [==============================] - 0s - loss: 27592168.6453     \n",
      "Epoch 132/170\n",
      "21992/21992 [==============================] - 0s - loss: 27474600.8025     \n",
      "Epoch 133/170\n",
      "21992/21992 [==============================] - 0s - loss: 27471551.3692     \n",
      "Epoch 134/170\n",
      "21992/21992 [==============================] - 0s - loss: 27324108.4009     \n",
      "Epoch 135/170\n",
      "21992/21992 [==============================] - 0s - loss: 27153255.1859     \n",
      "Epoch 136/170\n",
      "21992/21992 [==============================] - 0s - loss: 27062011.1502     \n",
      "Epoch 137/170\n",
      "21992/21992 [==============================] - 0s - loss: 27091034.7930     \n",
      "Epoch 138/170\n",
      "21992/21992 [==============================] - 0s - loss: 27076262.0546     \n",
      "Epoch 139/170\n",
      "21992/21992 [==============================] - 0s - loss: 27011427.8487     \n",
      "Epoch 140/170\n",
      "21992/21992 [==============================] - 0s - loss: 26948551.2615     \n",
      "Epoch 141/170\n",
      "21992/21992 [==============================] - 0s - loss: 26823719.9433     \n",
      "Epoch 142/170\n",
      "21992/21992 [==============================] - 0s - loss: 26789084.1775     \n",
      "Epoch 143/170\n",
      "21992/21992 [==============================] - 0s - loss: 26700199.3889     \n",
      "Epoch 144/170\n",
      "21992/21992 [==============================] - 0s - loss: 26690595.7112     \n",
      "Epoch 145/170\n",
      "21992/21992 [==============================] - 0s - loss: 26661940.9756     \n",
      "Epoch 146/170\n",
      "21992/21992 [==============================] - 0s - loss: 26488368.8592     \n",
      "Epoch 147/170\n",
      "21992/21992 [==============================] - 0s - loss: 26400815.9498     \n",
      "Epoch 148/170\n",
      "21992/21992 [==============================] - 0s - loss: 26272532.3470     \n",
      "Epoch 149/170\n",
      "21992/21992 [==============================] - 0s - loss: 26215389.6741     \n",
      "Epoch 150/170\n",
      "21992/21992 [==============================] - 0s - loss: 26201853.9687     \n",
      "Epoch 151/170\n",
      "21992/21992 [==============================] - 0s - loss: 25972759.3416     \n",
      "Epoch 152/170\n",
      "21992/21992 [==============================] - 0s - loss: 26124854.6177     \n",
      "Epoch 153/170\n",
      "21992/21992 [==============================] - 0s - loss: 26119485.9658     \n",
      "Epoch 154/170\n",
      "21992/21992 [==============================] - 0s - loss: 25930823.9549     \n",
      "Epoch 155/170\n",
      "21992/21992 [==============================] - 0s - loss: 25744787.5482     \n",
      "Epoch 156/170\n",
      "21992/21992 [==============================] - 0s - loss: 25926492.1506     \n",
      "Epoch 157/170\n",
      "21992/21992 [==============================] - 0s - loss: 25646099.4915     \n",
      "Epoch 158/170\n",
      "21992/21992 [==============================] - 0s - loss: 25894958.0888     \n",
      "Epoch 159/170\n",
      "21992/21992 [==============================] - 0s - loss: 25584489.9738     \n",
      "Epoch 160/170\n",
      "21992/21992 [==============================] - 0s - loss: 25603006.4773     \n",
      "Epoch 161/170\n",
      "21992/21992 [==============================] - 0s - loss: 25585605.7301     \n",
      "Epoch 162/170\n",
      "21992/21992 [==============================] - 0s - loss: 25483494.9895     \n",
      "Epoch 163/170\n",
      "21992/21992 [==============================] - 0s - loss: 25486370.6162     \n",
      "Epoch 164/170\n",
      "21992/21992 [==============================] - 0s - loss: 25276707.3074     \n",
      "Epoch 165/170\n",
      "21992/21992 [==============================] - 0s - loss: 25417539.0025     \n",
      "Epoch 166/170\n",
      "21992/21992 [==============================] - 0s - loss: 25231754.6497     \n",
      "Epoch 167/170\n",
      "21992/21992 [==============================] - 0s - loss: 25246455.9338     \n",
      "Epoch 168/170\n",
      "21992/21992 [==============================] - 0s - loss: 25028243.1451     \n",
      "Epoch 169/170\n",
      "21992/21992 [==============================] - 0s - loss: 25009236.9516     \n",
      "Epoch 170/170\n",
      "21992/21992 [==============================] - 0s - loss: 24865341.6370     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3558a7da50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(200, activation='relu', input_dim=vec_length))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(vec_length, activation='linear'))\n",
    "\n",
    "# For a mean squared error regression problem\n",
    "model.compile(optimizer='rmsprop', loss='mse')\n",
    "model.fit(mono_input, mono_output, epochs=170, batch_size=128)\n",
    "\n",
    "# print(np.max(mono_input))\n",
    "# print(np.min(mono_input))\n",
    "# print(np.max(mono_output))\n",
    "# print(np.min(mono_output))\n",
    "# print(type(mono_input[0,1]))\n",
    "\n",
    "# fi64 = np.finfo(np.float64)\n",
    "# print(fi64.min)\n",
    "# print(fi64.max)\n",
    "\n",
    "# test_a = np.array([1,2,3,4])\n",
    "# test_b = np.array([1,2,3,4,5])+8\n",
    "# test_list = [test_a, test_b]\n",
    "# test_vec = np.concatenate(test_list)\n",
    "# print(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21992, 276)\n",
      "(1, 4838240)\n",
      "coeffs shape: [44, 44, 69, 119]\n",
      "coeffs type: <type 'numpy.float32'>\n",
      "2\n",
      "reconstruction shape: (2419120, 2)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(mono_input)\n",
    "print(predictions.shape)\n",
    "\n",
    "reconstruction_array = []\n",
    "for i in range(predictions.shape[0]):\n",
    "    # don't forget to scale up again\n",
    "    coeffs = vector_to_list(predictions[i,:]) # *100000\n",
    "    rec_arr = np.array([pywt.waverec(coeffs, wavetype)]).astype('int16')\n",
    "    reconstruction_array.append(rec_arr)\n",
    "\n",
    "reconstruction_array = np.concatenate(reconstruction_array,axis=1)\n",
    "print(reconstruction_array.shape)\n",
    "# write_array = np.reshape(reconstruction_array, (-1,2))\n",
    "rec_split = np.split(reconstruction_array.T, 2)\n",
    "print(\"coeffs shape: \" + str([len(j) for j in coeffs]))\n",
    "print(\"coeffs type: \" + str(type(coeffs[0][0])))\n",
    "print(len(rec_split))\n",
    "\n",
    "write_array = np.concatenate((rec_split[0], rec_split[1]),axis=1)\n",
    "print('reconstruction shape: ' + str(write_array.shape))\n",
    "\n",
    "# output wav for auditory test\n",
    "wavfile.write('output/recons_network1.wav', input_rate, write_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-12546.151, -21841.895537893095)\n",
      "(-12300.193, -25994.390528711374)\n",
      "(-13096.056, -25919.847542833704)\n",
      "(-11806.011, -21543.315618397464)\n",
      "(-12554.108, -21505.014979520016)\n",
      "(-12203.805, -25559.021594466827)\n",
      "(-13296.866, -26435.884076893097)\n",
      "(-11588.147, -21556.617028473964)\n",
      "(-12344.221, -21099.510140276274)\n",
      "(-12327.898, -25397.922479057059)\n",
      "(-13052.554, -26409.344135687548)\n",
      "(-11975.097, -22186.119901553058)\n",
      "(-12353.179, -21030.754211483098)\n",
      "(-12393.01, -25005.230420325308)\n",
      "(-12885.297, -26537.149251561692)\n",
      "(-12378.774, -22657.534608385726)\n",
      "(-11328.92, -21891.075191750744)\n",
      "(-10446.564, -16759.623124997368)\n",
      "(-9580.1895, -11632.321997361958)\n",
      "(-9562.8027, -7238.5900644988033)\n",
      "(-11810.074, -7480.411365728598)\n",
      "(-10432.397, -7410.5474593182189)\n",
      "(-11999.791, -7879.4811802494678)\n",
      "(-12263.876, -5969.4594229938266)\n",
      "(-12586.295, -2633.9942673266751)\n",
      "(-10762.395, 578.61539950483518)\n",
      "(-10507.652, 3993.4295463815024)\n",
      "(-9639.9551, 6811.2403770892724)\n",
      "(-8441.5664, 7713.4200542717281)\n",
      "(-4737.3506, 5994.9390380683662)\n",
      "(599.88605, 3434.685343668817)\n",
      "(-333.29388, -83.059235187786953)\n",
      "(-278.7157, -5243.3532995427513)\n",
      "(-99.171738, -12015.342785520903)\n",
      "(-1985.382, -18852.989911134991)\n",
      "(-7669.2261, -26121.612570816775)\n",
      "(-11441.045, -29182.772527380977)\n",
      "(-12860.938, -31946.329694072861)\n",
      "(-17000.549, -34147.540860315901)\n",
      "(-18865.018, -35413.113962773954)\n",
      "(-22684.711, -30116.565852526823)\n",
      "(-21237.74, -24405.22486963655)\n",
      "(-20167.373, -25583.747086175565)\n",
      "(-21020.744, -23214.694095218652)\n",
      "(414.94211, 64.60004510540449)\n",
      "(-685.37939, -189.05100395177783)\n",
      "(-1304.0724, -260.73766631048682)\n",
      "(925.78064, 1011.2347650895505)\n",
      "(486.69476, 896.13758073587474)\n",
      "(-846.43683, -438.62315693886183)\n",
      "(-1054.9849, -221.20128118919033)\n",
      "(1377.6885, 1117.1712866732041)\n",
      "(510.92175, 441.90458685495707)\n",
      "(-323.46304, -138.08840492992596)\n",
      "(-30.036377, 616.10000416026423)\n",
      "(-238.62651, -1627.9508183081637)\n",
      "(-585.52405, 60.094048882065387)\n",
      "(486.94241, 2249.6322148584281)\n",
      "(-58.234016, 905.65356587526151)\n",
      "(527.89099, -1407.9045058022814)\n",
      "(141.62796, 859.3207652153967)\n",
      "(-586.91425, -213.49348201027604)\n",
      "(823.31335, -215.81349958705633)\n",
      "(-292.22382, -76.755014076246511)\n",
      "(-573.55316, 916.47083299600035)\n",
      "(-420.65979, 1082.8106968090387)\n",
      "(-582.29578, -364.03455930768206)\n",
      "(537.63251, -157.08162745589951)\n",
      "(235.29895, -140.03078529438974)\n",
      "(40.351089, 103.89458316696465)\n",
      "(465.75693, 348.66197765242725)\n",
      "(-840.77057, -490.50434369648895)\n",
      "(1189.0463, 1199.3419815328036)\n",
      "(33.922134, 1086.9199022343998)\n",
      "(-423.89685, -1896.7564464048967)\n",
      "(185.61334, 829.73705610458319)\n",
      "(85.276535, 1551.9235682668839)\n",
      "(-735.69147, -1089.1943844509872)\n",
      "(748.33569, -1322.6368122730591)\n",
      "(-658.23517, -255.46539835643469)\n",
      "(286.1384, 2458.4761982423706)\n",
      "(-257.11044, -271.75374599524491)\n",
      "(868.78503, -1294.7820497457542)\n",
      "(-991.53387, -346.57619591074695)\n",
      "(1124.3525, 1473.9941309665483)\n",
      "(-544.16473, -981.81968590553697)\n",
      "(-531.60883, -1566.8959091102511)\n",
      "(644.08478, 1121.3307973149094)\n",
      "(-441.38397, -108.09833321447029)\n",
      "(425.65878, 57.38639888580974)\n",
      "(46.027473, 255.60391344920652)\n",
      "(30.302277, -599.98136943677287)\n",
      "(4.8239474, 149.40145048017337)\n",
      "(242.86769, -136.68105866636262)\n",
      "(-226.33716, 394.49314144103414)\n",
      "(199.16574, -77.425963651780904)\n",
      "(-241.2785, -3.6040466403881979)\n",
      "(152.85487, -116.42441309721048)\n",
      "(-112.06095, 381.08627554215224)\n",
      "(251.24402, -1030.6685493743948)\n",
      "(-184.85783, 839.5278196112688)\n",
      "(58.101212, -541.37268069976358)\n",
      "(129.51781, 551.77642411583668)\n",
      "(-478.31357, -169.99142424811041)\n",
      "(459.33231, -122.14600353639894)\n",
      "(-240.57651, -59.352096877997639)\n",
      "(178.73872, 455.60570780689346)\n",
      "(-57.464695, -161.19945501774509)\n",
      "(-100.4156, 215.01437564847018)\n",
      "(112.92257, -192.22017996554078)\n",
      "(131.93658, -64.30366648431621)\n",
      "(88.637154, 248.21759939532407)\n",
      "(-210.10724, -302.09612681166578)\n",
      "(-43.112396, 98.849645869048615)\n",
      "(-68.859818, -131.21684409837897)\n",
      "(83.449097, 193.97890653036939)\n",
      "(-282.24884, -121.01495117870756)\n",
      "(517.29034, -67.910368473273891)\n",
      "(-508.5242, 297.30136279004245)\n",
      "(229.85994, -560.08219869710422)\n",
      "(-274.39832, 669.85493753616117)\n",
      "(77.327011, -177.76860798362725)\n",
      "(-262.8168, -195.33996904674521)\n",
      "(710.02905, 278.63456247028182)\n",
      "(-381.7023, -205.75794420138479)\n",
      "(300.69821, 55.393782000789621)\n",
      "(-314.39612, 79.069360651836689)\n",
      "(236.01752, -82.866648793436795)\n",
      "(-63.638855, -10.002465759844506)\n",
      "(59.782001, -4.3028419855729121)\n",
      "(262.2486, -110.51976043750892)\n",
      "(-275.4826, 80.246341893242942)\n",
      "(222.04558, -86.696733734903532)\n",
      "(-85.049942, -123.71994466954364)\n",
      "(28.316856, 119.32852627828666)\n",
      "(9.2745199, 545.30524514220019)\n",
      "(-306.54739, -179.10604319190625)\n",
      "(-229.31897, 536.47007713792709)\n",
      "(90.049149, -1270.3351796073034)\n",
      "(-419.8721, 1104.553248039326)\n",
      "(318.71228, -900.76607905243293)\n",
      "(-217.96048, 258.09130885247129)\n",
      "(163.45071, 359.60570072005402)\n",
      "(228.77049, -519.31052240229474)\n",
      "(-93.374763, 406.92177339562397)\n",
      "(-72.018135, -1282.7096061942293)\n",
      "(254.36867, 2015.3497584644138)\n",
      "(151.42854, -1062.944177649731)\n",
      "(-91.388512, 577.21397335228289)\n",
      "(-184.15956, -229.86841941866626)\n",
      "(-116.63423, -854.20587465725157)\n",
      "(133.87744, 479.24370336180721)\n",
      "(107.26897, 418.99573320012382)\n",
      "(-238.646, -313.58412822775432)\n",
      "(53.745914, 223.76870708565968)\n",
      "(216.00522, -578.88783711442727)\n",
      "(-226.57175, 987.48618033553385)\n",
      "(193.73174, -10.498877588011281)\n",
      "(-387.07013, 67.679217491844724)\n",
      "(-141.11519, 56.234857454973572)\n",
      "(389.19867, 135.62099405645196)\n",
      "(-17.694365, -119.06228456478496)\n",
      "(10.305668, -91.600684653667074)\n",
      "(375.54263, -76.076429075582325)\n",
      "(-263.54465, -7.7256968216762454)\n",
      "(226.4628, 218.16478361734318)\n",
      "(-485.51837, -5.333609513223343)\n",
      "(-126.14699, 71.211598301450408)\n",
      "(27.351368, -96.702615142644703)\n",
      "(25.90167, -168.89109910993915)\n",
      "(-48.004177, -0.40941172135866827)\n",
      "(-47.047256, 54.334866100633207)\n",
      "(44.456139, 72.798520045470852)\n",
      "(164.33998, -4.4528555316804486)\n",
      "(-200.09888, 161.29876927872243)\n",
      "(-159.31969, -156.26667254605013)\n",
      "(233.12492, 46.178603765875643)\n",
      "(190.52463, -227.11996963758665)\n",
      "(217.61508, 289.97863721146587)\n",
      "(379.36285, -256.74244893335981)\n",
      "(-180.31697, -25.821420294938452)\n",
      "(-51.217201, 248.89454673427701)\n",
      "(-188.94885, 116.9038542209738)\n",
      "(102.31943, -112.39277203497571)\n",
      "(-213.55531, -156.73925466590163)\n",
      "(138.30588, -118.88531552991452)\n",
      "(240.03897, 129.1557221790662)\n",
      "(-244.82312, 125.92174174218502)\n",
      "(-113.76228, 19.607659077970137)\n",
      "(243.92039, -55.509407044933369)\n",
      "(164.54854, 12.835374414662068)\n",
      "(-93.567932, -115.74834993886888)\n",
      "(58.982155, -4.2621823470116631)\n",
      "(-159.41197, 61.61575889240904)\n",
      "(3.5703807, 20.227904051078685)\n",
      "(83.107666, -3.9191715147689132)\n",
      "(-446.20865, 15.815100734032285)\n",
      "(306.53238, -6.039166262616237)\n",
      "(-363.78143, -30.887707927716722)\n",
      "(230.27113, 18.41550844051535)\n",
      "(201.25854, -1.725295108698301)\n",
      "(319.21741, 7.9706064935384049)\n",
      "(-189.07706, 8.3255217645798343)\n",
      "(-214.63632, -16.694539993974281)\n",
      "(-409.68912, 11.970653117561048)\n",
      "(365.05585, 21.032771115599015)\n",
      "(270.86407, -3.9939848320534979)\n",
      "(-82.826286, -8.9105995459163339)\n",
      "(-58.965347, -26.801616266904407)\n",
      "(-129.80919, -14.54349391381824)\n",
      "(175.4978, 12.572091103950669)\n",
      "(185.03831, 60.652761210695751)\n",
      "(40.012249, -16.845213358271)\n",
      "(-299.01422, -30.529914154202132)\n",
      "(-266.55939, 9.4170199461302957)\n",
      "(-58.656437, -49.088876697847937)\n",
      "(250.40219, 13.932736458721516)\n",
      "(204.09366, 44.039567256784224)\n",
      "(30.69503, -1.1515981128884609)\n",
      "(48.715839, -0.13862676039535204)\n",
      "(314.07828, -1.7580510269851446)\n",
      "(-372.4632, -14.051449883399743)\n",
      "(321.99591, -10.9497113617659)\n",
      "(36.266201, -12.569371334935166)\n",
      "(-154.75476, 24.114229357170206)\n",
      "(-82.597389, -20.890452451287995)\n",
      "(-113.11523, 23.646949365474949)\n",
      "(-52.704388, 0.61198991370106648)\n",
      "(97.227592, -2.4421611328053436)\n",
      "(-118.73247, 14.640947061326454)\n",
      "(110.81682, -22.408157459303425)\n",
      "(-138.58795, -18.722508799728562)\n",
      "(-278.14197, 0.67488517575383633)\n",
      "(-28.699711, 19.658807173460097)\n",
      "(-40.920158, 43.584300812758272)\n",
      "(42.552338, -27.698151627056994)\n",
      "(-76.098236, -9.3264519452788441)\n",
      "(61.800049, -43.329022942209633)\n",
      "(29.689049, -24.741512439932816)\n",
      "(276.29321, 63.066027828321666)\n",
      "(-113.16667, 29.592851034097055)\n",
      "(88.541786, -14.423542080912764)\n",
      "(-190.69342, 79.611747757682977)\n",
      "(-164.26289, -102.95164042078626)\n",
      "(35.201836, -25.683910134894017)\n",
      "(314.41757, 2.632864278931804)\n",
      "(10.010618, -56.264463999976805)\n",
      "(-77.121201, 142.9787070932409)\n",
      "(131.10146, -188.60023937709659)\n",
      "(13.440485, 367.74962726995568)\n",
      "(309.13153, -149.65209882447635)\n",
      "(-245.93738, -241.46108894393046)\n",
      "(40.828804, 71.976530366067735)\n",
      "(-44.503979, 154.00826521136705)\n",
      "(-52.258545, 27.545371483419931)\n",
      "(-277.36151, -122.40763988087268)\n",
      "(204.49124, -40.778498227207855)\n",
      "(98.175514, -52.398639080723491)\n",
      "(132.67841, 169.91854433084194)\n",
      "(-331.30643, 71.489682397662023)\n",
      "(325.94263, -53.880638789670428)\n",
      "(-163.82776, -15.690545504087)\n",
      "(-197.70425, -189.78059544594586)\n",
      "(-16.905523, 86.880876936322579)\n",
      "(-269.33807, 5.6823664791780049)\n",
      "(484.00131, -22.138560417893522)\n",
      "(-33.847023, 165.83210027141288)\n",
      "(133.26997, 49.415065484017845)\n",
      "(-125.03117, -156.42449892060614)\n",
      "(292.5636, 16.522279263697186)\n",
      "(-144.78831, -131.8362134841779)\n",
      "(-91.338112, 102.16829587618686)\n",
      "(147.20744, -87.171803934702567)\n",
      "(-177.79706, 133.75579130576435)\n",
      "(-160.52991, 153.63388993890177)\n",
      "(-96.271561, -154.6010028524299)\n"
     ]
    }
   ],
   "source": [
    "for i in range(vec_length):\n",
    "    print(predictions[10,i], mono_output[10,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now for the second (LSTM) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "95000*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_down(data):\n",
    "    # -95000, 95000 just fits over the max and min\n",
    "    return (data/190000.0)+0.5\n",
    "\n",
    "def scale_up(data):\n",
    "#     print(np.min(data))\n",
    "    return (data-0.5)*190000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0555263969294\n",
      "0.948735158801\n",
      "('nb sequences:', 21952)\n",
      "(21952, 276)\n",
      "(21952, 40, 276)\n",
      "<type 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "# pre-process into sequences\n",
    "# first we need to scale (lstm doesn't like huge inputs)\n",
    "scaled_in = scale_down(mono_input)\n",
    "scaled_out = scale_down(mono_output)\n",
    "\n",
    "print(np.min(scaled_out))\n",
    "print(np.max(scaled_out))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 1\n",
    "vec_sequences = []\n",
    "next_vecs = []\n",
    "for i in range(0, len(scaled_in) - maxlen, step):\n",
    "#     vec_sequences.append(scaled_in[i: i + maxlen])\n",
    "#     next_vecs.append(scaled_out[i + maxlen])\n",
    "    vec_sequences.append(mono_input[i: i + maxlen])\n",
    "    next_vecs.append(mono_output[i + maxlen])\n",
    "vec_sequences = np.array(vec_sequences)\n",
    "next_vecs = np.array(next_vecs)\n",
    "print('nb sequences:', len(vec_sequences))\n",
    "# print(next_vecs[0].shape)\n",
    "# print(vec_sequences[0].shape)\n",
    "print(next_vecs.shape)\n",
    "print(vec_sequences.shape)\n",
    "print(type(next_vecs[0,0]))\n",
    "\n",
    "# x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "# y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Epoch 1/20\n",
      "21952/21952 [==============================] - 14s - loss: 61110877.4461    \n",
      "Epoch 2/20\n",
      "21952/21952 [==============================] - 14s - loss: 53264054.7755    \n",
      "Epoch 3/20\n",
      "21952/21952 [==============================] - 13s - loss: 51507198.6472    \n",
      "Epoch 4/20\n",
      "21952/21952 [==============================] - 13s - loss: 51195516.7230    \n",
      "Epoch 5/20\n",
      "21952/21952 [==============================] - 13s - loss: 51402505.9009    \n",
      "Epoch 6/20\n",
      "21952/21952 [==============================] - 13s - loss: 50947523.1953    \n",
      "Epoch 7/20\n",
      "21952/21952 [==============================] - 13s - loss: 50998582.4140    \n",
      "Epoch 8/20\n",
      "21952/21952 [==============================] - 13s - loss: 50700983.5335    \n",
      "Epoch 9/20\n",
      "21952/21952 [==============================] - 13s - loss: 50668655.2070    \n",
      "Epoch 10/20\n",
      "21952/21952 [==============================] - 13s - loss: 50279237.1778    \n",
      "Epoch 11/20\n",
      "21952/21952 [==============================] - 13s - loss: 49923852.3499    \n",
      "Epoch 12/20\n",
      "21952/21952 [==============================] - 13s - loss: 49761645.0845    \n",
      "Epoch 13/20\n",
      "21952/21952 [==============================] - 13s - loss: 49295271.7668    \n",
      "Epoch 14/20\n",
      "21952/21952 [==============================] - 14s - loss: 49011198.4606    \n",
      "Epoch 15/20\n",
      "21952/21952 [==============================] - 13s - loss: 49077067.7085    \n",
      "Epoch 16/20\n",
      "21952/21952 [==============================] - 13s - loss: 48874294.6939    \n",
      "Epoch 17/20\n",
      "21952/21952 [==============================] - 14s - loss: 48899928.2566    \n",
      "Epoch 18/20\n",
      "21952/21952 [==============================] - 14s - loss: 48590737.6793    \n",
      "Epoch 19/20\n",
      "21952/21952 [==============================] - 13s - loss: 48486510.4373    \n",
      "Epoch 20/20\n",
      "21952/21952 [==============================] - 13s - loss: 48533872.1166    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f34cb859bd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Define an input sequence and process it.\n",
    "# encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "# encoder = LSTM(latent_dim, return_state=True)\n",
    "# encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# # We discard `encoder_outputs` and only keep the states.\n",
    "# encoder_states = [state_h, state_c]\n",
    "\n",
    "# # Set up the decoder, using `encoder_states` as initial state.\n",
    "# decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# # We set up our decoder to return full output sequences,\n",
    "# # and to return internal states as well. We don't use the \n",
    "# # return states in the training model, but we will use them in inference.\n",
    "# decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "# decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "#                                      initial_state=encoder_states)\n",
    "# decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "# decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# # Define the model that will turn\n",
    "# # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "# model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(300, input_shape=(maxlen, vec_length)))\n",
    "\n",
    "lstm_model.add(Dense(200, activation='relu', input_dim=vec_length))\n",
    "lstm_model.add(Dense(200, activation='relu'))\n",
    "lstm_model.add(Dense(vec_length, activation='linear'))\n",
    "\n",
    "# For a mean squared error regression problem\n",
    "lstm_model.compile(optimizer='rmsprop', loss='mse')\n",
    "\n",
    "# lstm_model.add(Dense(vec_length))\n",
    "# # lstm_model.add(Activation('softmax'))\n",
    "# lstm_model.add(Activation(\"linear\"))\n",
    "\n",
    "\n",
    "# # lstm_model.add(Activation(\"sigmoid\")) \n",
    "\n",
    "# optimizer = RMSprop(lr=0.1)\n",
    "# lstm_model.compile(loss='mse', optimizer=optimizer)\n",
    "\n",
    "lstm_model.fit(vec_sequences, next_vecs, batch_size=128, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.00000000e+03  -2.34235000e+05   5.46660000e+04  -1.23000000e+02\n",
      "    2.22000000e+02]\n",
      " [  1.00000000e+03  -2.34235000e+05   5.46660000e+04  -1.23000000e+02\n",
      "    2.22000000e+02]]\n"
     ]
    }
   ],
   "source": [
    "e_test = np.array([[1000,-234235,54666,-123,222],[1000,-234235,54666,-123,222]])\n",
    "low_e = scale_down(e_test)\n",
    "high_e = scale_up(low_e)\n",
    "print(high_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--RAW PREDICTION DATA--\n",
      "(21952, 276)\n",
      "min, max\n",
      "(-26901.053, 29176.084)\n",
      "mean\n",
      "134.324\n",
      "--TARGET DATA--\n",
      "(21952, 276)\n",
      "min, max\n",
      "(-84449.9845834062, 85259.680172221881)\n",
      "mean\n",
      "102.791788898\n",
      "--SCALED UP PREDICTION--\n",
      "(21952, 276)\n",
      "min, max\n",
      "(-5.111295e+09, 5.543361e+09)\n",
      "--RAW TARGET--\n",
      "(21992, 276)\n",
      "min, max\n",
      "(-84449.9845834062, 85259.680172221881)\n",
      "--SCALED UP TARGET--\n",
      "(21952, 276)\n",
      "min, max\n",
      "(-16045592070.847178, 16199244232.722157)\n",
      "reconstruction done\n",
      "coeffs shape: [44, 44, 69, 119]\n",
      "coeffs type: <type 'numpy.float32'>\n",
      "2\n",
      "reconstruction shape: (2414720, 2)\n"
     ]
    }
   ],
   "source": [
    "predictions = lstm_model.predict(vec_sequences)\n",
    "print(\"--RAW PREDICTION DATA--\")\n",
    "print(predictions.shape)\n",
    "print(\"min, max\")\n",
    "print(np.min(predictions),np.max(predictions))\n",
    "print(\"mean\")\n",
    "print(np.mean(predictions))\n",
    "\n",
    "print(\"--TARGET DATA--\")\n",
    "print(next_vecs.shape)\n",
    "print(\"min, max\")\n",
    "print(np.min(next_vecs),np.max(next_vecs))\n",
    "print(\"mean\")\n",
    "print(np.mean(next_vecs))\n",
    "\n",
    "scaled_up_predictions = scale_up(predictions)\n",
    "print(\"--SCALED UP PREDICTION--\")\n",
    "print(scaled_up_predictions.shape)\n",
    "print(\"min, max\")\n",
    "print(np.min(scaled_up_predictions),np.max(scaled_up_predictions))\n",
    "\n",
    "print(\"--RAW TARGET--\")\n",
    "print(mono_output.shape)\n",
    "print(\"min, max\")\n",
    "print(np.min(mono_output),np.max(mono_output))\n",
    "\n",
    "scaled_up_target = scale_up(next_vecs)\n",
    "print(\"--SCALED UP TARGET--\")\n",
    "print(scaled_up_target.shape)\n",
    "print(\"min, max\")\n",
    "print(np.min(scaled_up_target),np.max(scaled_up_target))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "reconstruction_array = []\n",
    "for i in range(predictions.shape[0]):\n",
    "    # don't forget to scale up again\n",
    "#     coeffs = vector_to_list(np.array(scale_up(predictions[i,:]),dtype=np.float64))\n",
    "#     coeffs = vector_to_list(scaled_up_predictions[i,:])\n",
    "    coeffs = vector_to_list(predictions[i,:])\n",
    "    rec_arr = np.array([pywt.waverec(coeffs, wavetype)]).astype('int16')\n",
    "    reconstruction_array.append(rec_arr)\n",
    "\n",
    "print(\"reconstruction done\")\n",
    "print(\"coeffs shape: \" + str([len(j) for j in coeffs]))\n",
    "print(\"coeffs type: \" + str(type(coeffs[0][0])))\n",
    "\n",
    "# scale it up before writing\n",
    "reconstruction_array = np.concatenate(reconstruction_array,axis=1)\n",
    "# scaled_up_out = scale_up(reconstruction_array)\n",
    "# print(\"max, min for original output\")\n",
    "# print(\"max, min for scaled up recon\")\n",
    "# print(np.max(coeffs[0]))\n",
    "# print(np.min(coeffs[0]))\n",
    "# print(reconstruction_array.shape)\n",
    "# print(\"max, min for original output\")\n",
    "# print(np.max(mono_output))\n",
    "# print(np.min(mono_output))\n",
    "# print(scaled_up_out.shape)\n",
    "# write_array = np.reshape(reconstruction_array, (-1,2))\n",
    "rec_split = np.split(reconstruction_array.T, 2)\n",
    "print(len(rec_split))\n",
    "\n",
    "write_array = np.concatenate((rec_split[0], rec_split[1]),axis=1)\n",
    "print('reconstruction shape: ' + str(write_array.shape))\n",
    "\n",
    "# output wav for auditory test\n",
    "wavfile.write('output/recons_network2.wav', input_rate, write_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3604.0366, -7490.6828929353187)\n",
      "(2507.4595, -5912.2729415973463)\n",
      "(2594.085, -7516.8136176023463)\n",
      "(3550.6235, -6028.3686456463065)\n",
      "(3649.1428, -7459.7528668926698)\n",
      "(2584.5444, -6136.8458790794875)\n",
      "(2537.9558, -7198.6403564400789)\n",
      "(3476.6135, -6424.2201194014115)\n",
      "(3685.7178, -7596.4223618263886)\n",
      "(2661.4863, -6092.0151177218213)\n",
      "(2468.5278, -7316.7494177943527)\n",
      "(3408.7156, -6248.7613679890674)\n",
      "(3758.1333, -7179.5513755415159)\n",
      "(2715.5466, -6529.9556985545269)\n",
      "(2471.4807, -6612.8048456565784)\n",
      "(3214.1348, -7512.2625524997884)\n",
      "(4068.0237, -4481.5947393439701)\n",
      "(4859.4004, 1346.0467971081464)\n",
      "(5561.0234, 9071.2642407207986)\n",
      "(6201.1562, 15294.536346507992)\n",
      "(6802.6401, 23511.451919276547)\n",
      "(7583.8374, 30222.238597602904)\n",
      "(8100.0815, 37505.944793658389)\n",
      "(8560.4141, 48117.050679664681)\n",
      "(9152.9619, 57053.184544768454)\n",
      "(9606.917, 56969.372515066039)\n",
      "(10164.006, 53179.053714181107)\n",
      "(10841.852, 45535.228353236977)\n",
      "(11335.428, 32094.745798399421)\n",
      "(11951.838, 19543.509182392063)\n",
      "(12484.518, 8109.5391681695901)\n",
      "(13079.618, -530.45241392318235)\n",
      "(13370.909, -6917.3968651933437)\n",
      "(13688.917, -10907.209648866894)\n",
      "(14167.401, -14018.945130519643)\n",
      "(14333.197, -13885.203296329692)\n",
      "(14568.169, -8555.1433909115476)\n",
      "(14692.979, -784.97934221414243)\n",
      "(14828.536, 8815.8738913563866)\n",
      "(15023.145, 16196.840151498753)\n",
      "(15068.842, 25099.229998566509)\n",
      "(15103.46, 28315.076434862138)\n",
      "(15121.854, 27980.202709993424)\n",
      "(15096.191, 29073.942848375882)\n",
      "(2.7180741, -292.34214937944131)\n",
      "(-5.4275584, 235.54339768686555)\n",
      "(100.568, -799.1835232668484)\n",
      "(-150.76027, -83.717027595641085)\n",
      "(-81.07991, -1108.9826729044355)\n",
      "(30.572224, 446.29652282319978)\n",
      "(98.572639, -793.54393093376234)\n",
      "(-136.41304, 183.38013169286839)\n",
      "(86.583939, -636.14436399548106)\n",
      "(-53.096134, 246.11603034788456)\n",
      "(-84.570938, -314.03720263142861)\n",
      "(-202.96721, 584.19625987911468)\n",
      "(22.808184, -337.5190564719407)\n",
      "(117.80031, -927.77100183408072)\n",
      "(-43.603333, 961.28947341750506)\n",
      "(-159.95407, 1345.111776993748)\n",
      "(-63.645138, 1314.6769966209663)\n",
      "(0.78204834, -1292.8563124954262)\n",
      "(9.1869307, 2043.6153284421955)\n",
      "(97.536255, -1071.7154449326486)\n",
      "(92.512817, -426.52109451596067)\n",
      "(53.274326, 57.310614563970169)\n",
      "(-55.657818, 12.369288398581357)\n",
      "(-61.085152, -121.1327211672433)\n",
      "(-37.37402, 25.257257293657137)\n",
      "(-57.726994, 8.6167737534699693)\n",
      "(-30.271799, -371.64206308303488)\n",
      "(-17.999994, 924.61143453629927)\n",
      "(42.104027, -1070.7512882084654)\n",
      "(-22.530369, 302.47218934697622)\n",
      "(130.61577, -133.70305682658721)\n",
      "(-131.49426, 104.02750428037484)\n",
      "(8.6858511, 30.335436896152622)\n",
      "(-54.203629, -126.9943806911031)\n",
      "(90.152054, 237.88947068759771)\n",
      "(-26.199837, 157.80647094341231)\n",
      "(-91.539047, -630.74054699820829)\n",
      "(52.824802, 590.5962349369313)\n",
      "(78.046944, -495.24595186085276)\n",
      "(32.918266, 337.25453476121771)\n",
      "(-59.893333, -267.22810783201538)\n",
      "(-25.807692, 222.26630360184416)\n",
      "(-9.2045298, 506.25122735355814)\n",
      "(-3.9203362, -482.86889528972694)\n",
      "(40.639252, -59.164771998935095)\n",
      "(-21.609304, 98.84283764964259)\n",
      "(-51.008366, -117.12862523466161)\n",
      "(69.204979, 576.52933627996879)\n",
      "(-43.333874, -134.34324756466705)\n",
      "(9.2621489, 273.96035249624998)\n",
      "(-50.884472, -374.29969712735567)\n",
      "(-5.2543325, 265.28930655465865)\n",
      "(80.328735, -115.63599833423673)\n",
      "(57.609951, -26.082515007839969)\n",
      "(-24.958214, 75.787835539077335)\n",
      "(3.5643003, -42.183969728440779)\n",
      "(-9.5534315, -100.59575235416547)\n",
      "(-131.16878, 151.20726036085603)\n",
      "(46.893337, -264.78792619941589)\n",
      "(10.02428, 29.075472016526593)\n",
      "(25.344423, 518.2797102380955)\n",
      "(111.55921, -269.54231483648476)\n",
      "(14.708262, 155.20159038043974)\n",
      "(88.395775, 211.85974158338499)\n",
      "(-102.53532, -796.39915337182094)\n",
      "(54.15641, 277.32460494878234)\n",
      "(-19.803804, 152.94014346154481)\n",
      "(-1.5039216, -352.58523116620256)\n",
      "(-47.209919, 790.85503959935727)\n",
      "(113.41795, -654.2251147581128)\n",
      "(16.626289, -169.15641140245981)\n",
      "(-27.940149, 133.83295071263049)\n",
      "(-11.436421, -810.06857365912413)\n",
      "(70.131149, 804.04875286384492)\n",
      "(-85.799507, -806.0679475997573)\n",
      "(85.042015, 597.82216611083197)\n",
      "(-50.730301, -877.95793778250254)\n",
      "(94.587502, 346.71431945179069)\n",
      "(-28.166174, -102.37691902703355)\n",
      "(10.265574, 23.902265726724934)\n",
      "(13.55499, 277.74017496935738)\n",
      "(-7.8091588, -79.546582744128784)\n",
      "(97.562462, -10.548513376978736)\n",
      "(-83.950859, 18.244476389778871)\n",
      "(22.034718, 103.55731213095562)\n",
      "(24.9688, -35.215771422831189)\n",
      "(-26.073412, -160.77350109829692)\n",
      "(79.833923, 67.837554855277631)\n",
      "(-23.848553, -118.8636286578313)\n",
      "(79.743942, 132.18617591947228)\n",
      "(-40.101723, 224.90087116605548)\n",
      "(-12.937679, -175.99478462988552)\n",
      "(17.549603, 317.57048254371927)\n",
      "(10.999821, -320.37058645242365)\n",
      "(37.914021, 305.11446483749006)\n",
      "(141.80157, -198.52919240123697)\n",
      "(7.7047677, -92.315142174376575)\n",
      "(-27.053225, 45.804009506756451)\n",
      "(25.04851, 37.002511646107273)\n",
      "(-110.54814, -107.27816419202354)\n",
      "(10.75663, 887.44693747278757)\n",
      "(-75.300865, -363.33954037164392)\n",
      "(45.401505, -184.22140309271791)\n",
      "(71.800606, 324.79010187613011)\n",
      "(-25.55006, -88.915091426415813)\n",
      "(-75.364624, -190.652891206189)\n",
      "(-20.22414, 182.28681402979126)\n",
      "(51.029369, 186.66593911243578)\n",
      "(72.169289, -790.59211683385229)\n",
      "(20.979176, 30.48942943358341)\n",
      "(27.187637, 189.25506651026427)\n",
      "(-29.477591, -237.98161186911776)\n",
      "(-14.062698, 290.91315755805823)\n",
      "(-17.298491, 29.701292700862684)\n",
      "(-18.470882, -70.561399170778913)\n",
      "(-64.618332, 40.228161813904741)\n",
      "(-8.3932304, -43.654485349845537)\n",
      "(-13.535178, 152.70371652106874)\n",
      "(-23.555613, -79.478090397578228)\n",
      "(-27.538561, 74.908523841746231)\n",
      "(21.565548, -32.314023573086871)\n",
      "(1.3701316, 59.815533470918012)\n",
      "(-1.9780995, -20.471399278700421)\n",
      "(-18.200497, 23.526511985640845)\n",
      "(-0.79786706, -21.236139715602498)\n",
      "(34.475048, 6.9217688559234105)\n",
      "(-16.446945, -14.854583794610738)\n",
      "(13.772288, 0.79044447010576679)\n",
      "(-1.9141194, -18.419138582339166)\n",
      "(50.622471, 4.521162757626259)\n",
      "(-44.925156, -22.238709693952305)\n",
      "(-10.079991, 15.162714743336148)\n",
      "(21.379629, -8.5084766621914714)\n",
      "(-34.662048, 18.31381150109473)\n",
      "(75.58799, -10.134727455062315)\n",
      "(-88.40023, 34.336043264964715)\n",
      "(80.426788, 76.146526693921246)\n",
      "(-43.792309, -64.486462864662556)\n",
      "(33.707268, 71.232280239135946)\n",
      "(-54.873524, -65.212458030402018)\n",
      "(37.922699, -12.868237787804699)\n",
      "(-30.363153, 7.1723650998784789)\n",
      "(12.590891, 5.6310412773745719)\n",
      "(-36.236263, -5.0524121528202981)\n",
      "(-54.946159, -52.565803893552541)\n",
      "(33.828098, 23.108152849845425)\n",
      "(-31.97575, -117.92792572864067)\n",
      "(50.169819, 33.148536849301166)\n",
      "(28.635437, -2.4136374433608112)\n",
      "(19.372892, 68.161656998710043)\n",
      "(38.833504, 44.28860893115786)\n",
      "(-38.692204, -150.98852952627291)\n",
      "(21.104109, 38.9242452259545)\n",
      "(-3.9737897, -217.64302347402324)\n",
      "(30.374115, 212.57386374797318)\n",
      "(-45.362175, -146.63827880429341)\n",
      "(32.981453, 94.061696910763132)\n",
      "(18.090738, -113.76977439648606)\n",
      "(-27.685219, 131.48602114988245)\n",
      "(17.135363, -14.66563742838926)\n",
      "(-23.151653, 52.114375014599545)\n",
      "(8.2826385, -57.862455866789716)\n",
      "(-3.9797065, -53.733707213935361)\n",
      "(-32.60194, 97.303369839086017)\n",
      "(2.8220108, -104.37831474830165)\n",
      "(26.365145, -43.854096256048059)\n",
      "(-13.884223, 16.641766368457056)\n",
      "(7.4990253, 63.150545214442282)\n",
      "(-38.327133, -64.372596105238244)\n",
      "(41.296841, 63.972037990373586)\n",
      "(-27.900476, -27.284123828035341)\n",
      "(-32.713902, 117.58383509477319)\n",
      "(19.650879, 71.2984698997398)\n",
      "(-22.955433, -42.770568284814168)\n",
      "(1.2383167, 25.999155388511376)\n",
      "(-6.2269526, -34.697630521481585)\n",
      "(0.67439961, 81.309998802552869)\n",
      "(39.548969, -29.2599571596243)\n",
      "(-39.934235, 73.115423227311794)\n",
      "(-1.853515, -16.906404743366576)\n",
      "(-55.446198, 10.875335551606163)\n",
      "(16.14485, 28.575503403930139)\n",
      "(16.384079, -1.0616501281378157)\n",
      "(-13.520678, 18.017439695881606)\n",
      "(34.026978, -0.28881221726552242)\n",
      "(-29.070143, -5.1471116949145204)\n",
      "(20.500479, -8.0863366645471508)\n",
      "(-9.5762377, 6.6894593910783966)\n",
      "(29.104797, -30.020698026266263)\n",
      "(-19.994833, 53.040622283484957)\n",
      "(30.73123, -17.924072121183169)\n",
      "(-52.302002, 33.226339720307408)\n",
      "(35.320305, -24.203931272935083)\n",
      "(-31.029417, -3.0702892399742714)\n",
      "(11.346125, -31.552374033207656)\n",
      "(-17.943258, 11.993585576004177)\n",
      "(22.028862, -6.6303335908260452)\n",
      "(-23.619545, -16.496960845879251)\n",
      "(3.0765543, 42.303797426506456)\n",
      "(-15.038428, -44.265591540708925)\n",
      "(-14.333976, 41.664714976500385)\n",
      "(-8.2466183, -39.110783080804083)\n",
      "(-11.180331, 48.327619689408316)\n",
      "(23.551067, -17.120795583185966)\n",
      "(-13.290203, 36.673427263869982)\n",
      "(-28.743782, -16.290748550968924)\n",
      "(45.491108, 32.850558435672909)\n",
      "(-47.081364, -2.050240239947291)\n",
      "(19.79439, 7.6243001411207612)\n",
      "(15.277212, 3.3323592192957023)\n",
      "(-51.137676, 12.810918807243992)\n",
      "(52.89592, -13.231882653436235)\n",
      "(-66.739548, 19.828749247689938)\n",
      "(101.88762, -50.810512232167788)\n",
      "(-114.46831, 14.44492748724052)\n",
      "(49.056011, -54.024870682243424)\n",
      "(-90.64267, 111.28889566650756)\n",
      "(105.96984, -74.782981905102574)\n",
      "(-86.012398, 64.484493060714826)\n",
      "(73.578773, -0.73771108003243668)\n",
      "(-72.35054, 5.1153437564412316)\n",
      "(-4.1079502, 103.09663819724922)\n",
      "(21.85862, -75.501145507436604)\n",
      "(-56.994221, 106.31994799684909)\n",
      "(54.147968, -86.744804173872609)\n",
      "(-27.639614, 0.18200584835722)\n",
      "(5.2024093, -8.9360888177598188)\n",
      "(14.119552, -85.034681027619584)\n",
      "(12.947894, 29.595340798783543)\n",
      "(-41.170918, 4.1228005438725992)\n",
      "(79.649414, -82.787517554585747)\n",
      "(-97.918045, 88.866980461134034)\n"
     ]
    }
   ],
   "source": [
    "up_again_test = scale_up(next_vecs)\n",
    "for i in range(vec_length):\n",
    "    print(predictions[0,i], next_vecs[0,i])\n",
    "#     print(next_vecs[10000,i])\n",
    "# print(predictions[10000,90:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions shape, max, min, type, example\n",
      "(21952, 276)\n",
      "29176.1\n",
      "-26901.1\n",
      "<type 'numpy.float32'>\n",
      "3604.04\n",
      "scaled down output shape, max, min, type, example\n",
      "(21952, 276)\n",
      "85259.6801722\n",
      "-84449.9845834\n",
      "<type 'numpy.float64'>\n",
      "-7490.68289294\n",
      "reconstruction done\n",
      "coeffs shape: [44, 44, 69, 119]\n",
      "coeffs type: <type 'numpy.float64'>\n",
      "reconstruction shape: (2414720, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"predictions shape, max, min, type, example\")\n",
    "print(predictions.shape)\n",
    "print(np.max(predictions))\n",
    "print(np.min(predictions))\n",
    "print(type(predictions[0,0]))\n",
    "print(predictions[0,0])\n",
    "\n",
    "print(\"scaled down output shape, max, min, type, example\")\n",
    "print(next_vecs.shape)\n",
    "print(np.max(next_vecs))\n",
    "print(np.min(next_vecs))\n",
    "print(type(next_vecs[0,0]))\n",
    "print(next_vecs[0,0])\n",
    "\n",
    "# reconstruct target output for bug\n",
    "\n",
    "\n",
    "reconstruction_array = []\n",
    "for i in range(predictions.shape[0]):\n",
    "    # don't forget to scale up again\n",
    "#     coeffs = vector_to_list(scale_up(next_vecs[i,:]))\n",
    "    coeffs = vector_to_list(next_vecs[i,:])\n",
    "    rec_arr = np.array([pywt.waverec(coeffs, wavetype)]).astype('int16')\n",
    "    reconstruction_array.append(rec_arr)\n",
    "\n",
    "print(\"reconstruction done\")\n",
    "print(\"coeffs shape: \" + str([len(j) for j in coeffs]))\n",
    "print(\"coeffs type: \" + str(type(coeffs[0][0])))\n",
    "\n",
    "# scale it up before writing\n",
    "reconstruction_array = np.concatenate(reconstruction_array,axis=1)\n",
    "\n",
    "# write_array = np.reshape(reconstruction_array, (-1,2))\n",
    "rec_split = np.split(reconstruction_array.T, 2)\n",
    "\n",
    "\n",
    "write_array = np.concatenate((rec_split[0], rec_split[1]),axis=1)\n",
    "print('reconstruction shape: ' + str(write_array.shape))\n",
    "\n",
    "# output wav for auditory test\n",
    "wavfile.write('output/recons_target_lstm.wav', input_rate, write_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 276)\n",
      "(21952, 40, 276)\n",
      "(21952, 40, 276, 1)\n"
     ]
    }
   ],
   "source": [
    "# let's try 2D convolutional first\n",
    "# turn vec_sequences into 2D-'image'\n",
    "# target is mono_output\n",
    "print(vec_sequences[1,:].shape)\n",
    "sequences_as_mat = np.array(vec_sequences)\n",
    "next_as_mat = np.array(next_vecs)\n",
    "print(sequences_as_mat.shape)\n",
    "# conv_in_shape = (40, 276)\n",
    "\n",
    "seq_added_dim = sequences_as_mat.reshape(sequences_as_mat.shape[0], 40, 276, 1)\n",
    "# next_added_dim = next_as_mat.reshape(next_as_mat.shape[0], 40, 276, 1)\n",
    "# X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "\n",
    "print(seq_added_dim.shape)\n",
    "# print(next_added_dim.shape)\n",
    "# (60000, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "21952/21952 [==============================] - 13s - loss: 63055875.8950    \n",
      "Epoch 2/80\n",
      "21952/21952 [==============================] - 13s - loss: 58284032.7347    \n",
      "Epoch 3/80\n",
      "21952/21952 [==============================] - 13s - loss: 55561545.9009    \n",
      "Epoch 4/80\n",
      "21952/21952 [==============================] - 13s - loss: 54406672.1633    \n",
      "Epoch 5/80\n",
      "21952/21952 [==============================] - 13s - loss: 53302959.0904    \n",
      "Epoch 6/80\n",
      "21952/21952 [==============================] - 13s - loss: 52531998.9271    \n",
      "Epoch 7/80\n",
      "21952/21952 [==============================] - 13s - loss: 51642611.5219    \n",
      "Epoch 8/80\n",
      "21952/21952 [==============================] - 13s - loss: 50932010.3324    \n",
      "Epoch 9/80\n",
      "21952/21952 [==============================] - 13s - loss: 50674016.0233    \n",
      "Epoch 10/80\n",
      "21952/21952 [==============================] - 13s - loss: 50104043.5219    \n",
      "Epoch 11/80\n",
      "21952/21952 [==============================] - 13s - loss: 49437530.1924    \n",
      "Epoch 12/80\n",
      "21952/21952 [==============================] - 13s - loss: 49107680.5131    \n",
      "Epoch 13/80\n",
      "21952/21952 [==============================] - 13s - loss: 48644479.2187    \n",
      "Epoch 14/80\n",
      "21952/21952 [==============================] - ETA: 0s - loss: 47999462.40 - 13s - loss: 48015194.3790    \n",
      "Epoch 15/80\n",
      "21952/21952 [==============================] - 13s - loss: 47851495.6268    \n",
      "Epoch 16/80\n",
      "21952/21952 [==============================] - 13s - loss: 47580807.9767    \n",
      "Epoch 17/80\n",
      "21952/21952 [==============================] - 13s - loss: 46904973.9708    \n",
      "Epoch 18/80\n",
      "21952/21952 [==============================] - 13s - loss: 46733855.6851    \n",
      "Epoch 19/80\n",
      "21952/21952 [==============================] - 13s - loss: 46424122.7755    \n",
      "Epoch 20/80\n",
      "21952/21952 [==============================] - 13s - loss: 46135693.0496    \n",
      "Epoch 21/80\n",
      "21952/21952 [==============================] - 13s - loss: 45958503.6385    \n",
      "Epoch 22/80\n",
      "21952/21952 [==============================] - 13s - loss: 45311735.7901    \n",
      "Epoch 23/80\n",
      "21952/21952 [==============================] - 13s - loss: 45034399.2070    \n",
      "Epoch 24/80\n",
      "21952/21952 [==============================] - 13s - loss: 44951742.2274    \n",
      "Epoch 25/80\n",
      "21952/21952 [==============================] - 13s - loss: 44745410.4023    \n",
      "Epoch 26/80\n",
      "21952/21952 [==============================] - 13s - loss: 43960407.0554    \n",
      "Epoch 27/80\n",
      "21952/21952 [==============================] - 13s - loss: 44005940.1983    \n",
      "Epoch 28/80\n",
      "21952/21952 [==============================] - 13s - loss: 43535380.5948    \n",
      "Epoch 29/80\n",
      "21952/21952 [==============================] - 13s - loss: 43424152.8746    \n",
      "Epoch 30/80\n",
      "21952/21952 [==============================] - 13s - loss: 43091791.3936    \n",
      "Epoch 31/80\n",
      "21952/21952 [==============================] - 13s - loss: 42562062.6706    \n",
      "Epoch 32/80\n",
      "21952/21952 [==============================] - 13s - loss: 42483404.4315    \n",
      "Epoch 33/80\n",
      "21952/21952 [==============================] - 13s - loss: 42206544.8047    \n",
      "Epoch 34/80\n",
      "21952/21952 [==============================] - 13s - loss: 41518842.5656    \n",
      "Epoch 35/80\n",
      "21952/21952 [==============================] - 13s - loss: 41234767.1953    \n",
      "Epoch 36/80\n",
      "21952/21952 [==============================] - 13s - loss: 40954569.0729    \n",
      "Epoch 37/80\n",
      "21952/21952 [==============================] - 13s - loss: 40749401.9475    \n",
      "Epoch 38/80\n",
      "21952/21952 [==============================] - 13s - loss: 40440831.1254    \n",
      "Epoch 39/80\n",
      "21952/21952 [==============================] - 13s - loss: 40210690.1108    \n",
      "Epoch 40/80\n",
      "21952/21952 [==============================] - 13s - loss: 39724709.3644    \n",
      "Epoch 41/80\n",
      "21952/21952 [==============================] - 13s - loss: 39223310.8688    \n",
      "Epoch 42/80\n",
      "21952/21952 [==============================] - 13s - loss: 38935177.7726    \n",
      "Epoch 43/80\n",
      "21952/21952 [==============================] - 13s - loss: 38648979.1137    \n",
      "Epoch 44/80\n",
      "21952/21952 [==============================] - 13s - loss: 38510019.6268    \n",
      "Epoch 45/80\n",
      "21952/21952 [==============================] - 13s - loss: 38019046.5656    \n",
      "Epoch 46/80\n",
      "21952/21952 [==============================] - 13s - loss: 37964304.8397    \n",
      "Epoch 47/80\n",
      "21952/21952 [==============================] - 13s - loss: 37852453.8309    \n",
      "Epoch 48/80\n",
      "21952/21952 [==============================] - 13s - loss: 37327474.4198    \n",
      "Epoch 49/80\n",
      "21952/21952 [==============================] - 13s - loss: 37240707.6385    \n",
      "Epoch 50/80\n",
      "21952/21952 [==============================] - 13s - loss: 36915932.8630    \n",
      "Epoch 51/80\n",
      "21952/21952 [==============================] - 13s - loss: 37207075.9534    \n",
      "Epoch 52/80\n",
      "21952/21952 [==============================] - 13s - loss: 36336648.6764    \n",
      "Epoch 53/80\n",
      "21952/21952 [==============================] - 13s - loss: 36315109.9592    \n",
      "Epoch 54/80\n",
      "21952/21952 [==============================] - 13s - loss: 36327690.3440    \n",
      "Epoch 55/80\n",
      "21952/21952 [==============================] - 13s - loss: 35610304.7930    \n",
      "Epoch 56/80\n",
      "21952/21952 [==============================] - 13s - loss: 35800636.5831    \n",
      "Epoch 57/80\n",
      "21952/21952 [==============================] - 13s - loss: 35645497.9125    \n",
      "Epoch 58/80\n",
      "21952/21952 [==============================] - 13s - loss: 35191873.3644    \n",
      "Epoch 59/80\n",
      "21952/21952 [==============================] - 13s - loss: 34967394.7055    \n",
      "Epoch 60/80\n",
      "21952/21952 [==============================] - 13s - loss: 34821287.5102    \n",
      "Epoch 61/80\n",
      "21952/21952 [==============================] - 13s - loss: 34604992.7697    \n",
      "Epoch 62/80\n",
      "21952/21952 [==============================] - 13s - loss: 34058823.7434    \n",
      "Epoch 63/80\n",
      "21952/21952 [==============================] - 13s - loss: 34387741.3236    \n",
      "Epoch 64/80\n",
      "21952/21952 [==============================] - 13s - loss: 34130406.4140    \n",
      "Epoch 65/80\n",
      "21952/21952 [==============================] - 13s - loss: 33762185.5510    \n",
      "Epoch 66/80\n",
      "21952/21952 [==============================] - 13s - loss: 33779281.1312    \n",
      "Epoch 67/80\n",
      "21952/21952 [==============================] - 13s - loss: 33678891.9184    \n",
      "Epoch 68/80\n",
      "21952/21952 [==============================] - 13s - loss: 33518908.0816    \n",
      "Epoch 69/80\n",
      "21952/21952 [==============================] - 13s - loss: 33053188.2682    \n",
      "Epoch 70/80\n",
      "21952/21952 [==============================] - 13s - loss: 33137496.6297    \n",
      "Epoch 71/80\n",
      "21952/21952 [==============================] - 13s - loss: 32804673.2245    \n",
      "Epoch 72/80\n",
      "21952/21952 [==============================] - 13s - loss: 32477029.6093    \n",
      "Epoch 73/80\n",
      "21952/21952 [==============================] - 13s - loss: 32581985.3761    \n",
      "Epoch 74/80\n",
      "21952/21952 [==============================] - 13s - loss: 32727447.1137    \n",
      "Epoch 75/80\n",
      "21952/21952 [==============================] - 13s - loss: 32330857.8542    \n",
      "Epoch 76/80\n",
      "21952/21952 [==============================] - 13s - loss: 32168370.8455    \n",
      "Epoch 77/80\n",
      "21952/21952 [==============================] - 13s - loss: 32170565.1195    \n",
      "Epoch 78/80\n",
      "21952/21952 [==============================] - 13s - loss: 31601804.4431    \n",
      "Epoch 79/80\n",
      "21952/21952 [==============================] - 13s - loss: 31460760.2216    \n",
      "Epoch 80/80\n",
      "21952/21952 [==============================] - 13s - loss: 31449638.1633    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f34465a4290>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# (OLD) build the model\n",
    "conv_model = Sequential()\n",
    "# conv(no.filters, filter_x, filter_y)\n",
    "conv_model.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(40,276,1)))\n",
    "conv_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "conv_model.add(Convolution2D(20, (7, 7), activation='relu'))\n",
    "conv_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "conv_model.add(Dropout(0.25))\n",
    "conv_model.add(Flatten())\n",
    "conv_model.add(Dense(200, activation='relu'))\n",
    "conv_model.add(Dropout(0.5))\n",
    "conv_model.add(Dense(200, activation='relu'))\n",
    "conv_model.add(Dropout(0.5))\n",
    "conv_model.add(Dense(200, activation='relu'))\n",
    "conv_model.add(Dropout(0.5))\n",
    "# conv_model.add(Dense(10, activation='softmax'))\n",
    "conv_model.add(Dense(vec_length, activation='linear'))\n",
    "\n",
    "# For a mean squared error regression problem\n",
    "conv_model.compile(optimizer='rmsprop', loss='mse')\n",
    "\n",
    "\n",
    "conv_model.fit(seq_added_dim, next_as_mat, batch_size=128, epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction done\n",
      "coeffs shape: [44, 44, 69, 119]\n",
      "coeffs type: <type 'numpy.float32'>\n",
      "2\n",
      "reconstruction shape: (2414720, 2)\n"
     ]
    }
   ],
   "source": [
    "conv_predictions = conv_model.predict(seq_added_dim)\n",
    "\n",
    "conv_reconstruction_array = []\n",
    "for i in range(conv_predictions.shape[0]):\n",
    "    # don't forget to scale up again\n",
    "#     coeffs = vector_to_list(np.array(scale_up(predictions[i,:]),dtype=np.float64))\n",
    "#     coeffs = vector_to_list(scaled_up_predictions[i,:])\n",
    "    coeffs = vector_to_list(conv_predictions[i,:])\n",
    "    rec_arr = np.array([pywt.waverec(coeffs, wavetype)]).astype('int16')\n",
    "    conv_reconstruction_array.append(rec_arr)\n",
    "\n",
    "print(\"reconstruction done\")\n",
    "print(\"coeffs shape: \" + str([len(j) for j in coeffs]))\n",
    "print(\"coeffs type: \" + str(type(coeffs[0][0])))\n",
    "\n",
    "# scale it up before writing\n",
    "conv_reconstruction_array = np.concatenate(conv_reconstruction_array,axis=1)\n",
    "\n",
    "rec_split = np.split(conv_reconstruction_array.T, 2)\n",
    "print(len(rec_split))\n",
    "\n",
    "write_array = np.concatenate((rec_split[0], rec_split[1]),axis=1)\n",
    "print('reconstruction shape: ' + str(write_array.shape))\n",
    "\n",
    "# output wav for auditory test\n",
    "wavfile.write('output/recons_network3.wav', input_rate, write_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# experimental model time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-26-8d40c74352c9>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-8d40c74352c9>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    exp_input =\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# define this without using sequential\n",
    "# this is necessary for residual connections\n",
    "\n",
    "# define input (same as conv approach)\n",
    "exp_input1 = Input(shape=(40,276,1), dtype='int32', name='main_input')\n",
    "# add convolutions\n",
    "conv1 = Convolution2D(32, (3, 3), activation='relu', input_shape=(40,276,1))(exp_input1)\n",
    "asdfsd =\n",
    "\n",
    "# concatenate original input and cov out, feed into dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEFTOVERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = []\n",
    "# a.append('asdsd')\n",
    "# a.append('adfgbsdfgbdfg')\n",
    "# a\n",
    "range(1,6,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DEPRECATED\n",
    "# reshapes total sequence into batches\n",
    "def get_batches(batch_size, sequence_length, input_sequence, output_sequence):\n",
    "    batch_amount = int(math.floor(total_samples/float(batch_size*sequence_length)))\n",
    "    input_batches = []\n",
    "    output_batches = []\n",
    "    print('creating ' + str(batch_amount) + ' batches')\n",
    "    for batch_index in range(1, batch_amount + 1):\n",
    "        print(batch_index)\n",
    "        for sequence_index in range(0,sequence_length*batch_size,sequence_length):\n",
    "            print(sequence_index)\n",
    "            sequence = input_sequence[sequence_index:sequence_index+sequence_length,:]\n",
    "            \n",
    "    \n",
    "# https://keras.io/layers/wrappers/\n",
    "\n",
    "# Consider a batch of 32 samples, where each sample is a sequence of 10 vectors of 16 dimensions. \n",
    "# The batch input shape of the layer is then (32, 10, 16), and the input_shape, not including \n",
    "# the samples dimension, is (10, 16)\n",
    "\n",
    "# batch_size = 32\n",
    "# sequence_length = 20   # no. of vectors in each sequence\n",
    "# vector_length = input_matrix.shape[1]\n",
    "# total_samples = input_matrix.shape[0]\n",
    "\n",
    "\n",
    "# input_batches, output_batches = get_batches(batch_size, sequence_length, input_matrix, output_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# build model\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(1, input_shape=(timesteps, data_dim), return_sequences=True))\n",
    "# model.add(TimeDistributed(Dense(vector_length), input_shape=(sequence_length, vector_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def group_list(l, group_size):\n",
    "#     \"\"\"\n",
    "#     :param l:           list\n",
    "#     :param group_size:  size of each group\n",
    "#     :return:            Yields successive group-sized lists from l.\n",
    "#     \"\"\"\n",
    "# #     res_arr = \n",
    "#     for i in xrange(0, len(l), group_size):\n",
    "#         yield l[i:i+group_size,:]\n",
    "\n",
    "# def get_np_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('leftovers')\n",
    "\n",
    "# max_features = 2124\n",
    "# maxlen = 80  # cut texts after this number of words (among top max_features most common words)\n",
    "# batch_size = 32\n",
    "# lstm_units = 250\n",
    "\n",
    "# # output_res = output_matrix #.reshape((-1, 1))\n",
    "\n",
    "# input_batches = group_list(input_matrix, batch_size)\n",
    "# output_batches = group_list(output_matrix, batch_size)\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(LSTM(max_features, input_dim=max_features))\n",
    "# model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "# model.fit(input_batches,output_batches, nb_epoch=10)\n",
    "\n",
    "\n",
    "\n",
    "# model.add(Embedding(max_features, lstm_units))\n",
    "# model.add(LSTM(lstm_units, dropout=0.2, recurrent_dropout=0.2, input_shape=(max_features, )))\n",
    "# model.add(Dense(max_features, activation='sigmoid'))\n",
    "\n",
    "# # try using different optimizers and different optimizer configs\n",
    "# model.compile(loss='sparse_categorical_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# print('Train...')\n",
    "# model.fit(input_matrix, output_res,\n",
    "# #           batch_size=batch_size,\n",
    "#           epochs=15,\n",
    "#           validation_data=(input_matrix, output_res))\n",
    "# score, acc = model.evaluate(input_matrix, output_res) #, batch_size=batch_size)\n",
    "# print('Test score:', score)\n",
    "# print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
